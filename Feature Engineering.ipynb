{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e0a214d0-64e0-4362-bf62-b6aaaafd68b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1.What is a parameter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc17ff70-9ee3-48a4-8693-04b1a4ac7143",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A parameter is a variable or value that is learned from the training\n",
    "#data and is used to define the behavior of a model. Parameters are \n",
    "#often adjusted during the training process to minimize the difference\n",
    "#between the model's predictions and the actual outcomes.\n",
    "\n",
    "#Types of Parameters in Machine Learning\n",
    "#1. Model parameters: These are the variables that are learned from \n",
    "#the training data and define the behavior of the model. Examples include:\n",
    "#    - Weights and biases in neural networks\n",
    "#    - Coefficients in linear regression models\n",
    "#2. Hyperparameters: These are parameters that are set before training\n",
    "#a model and control the learning process. Examples include:\n",
    "#    - Learning rate\n",
    "#    - Number of hidden layers in a neural network\n",
    "#    - Regularization strength\n",
    "\n",
    "#Key Characteristics of Parameters in Machine Learning\n",
    "#1. Learned from data: Model parameters are learned from the \n",
    "#training data.\n",
    "#2. Define model behavior: Parameters define the behavior of a \n",
    "#model and influence its predictions.\n",
    "#3. Adjusted during training: Model parameters are adjusted during \n",
    "#the training process to minimize the loss function.\n",
    "\n",
    "#Example of Parameters in Machine Learning\n",
    "#In a simple linear regression model, the parameters are the coefficients\n",
    "#(slope and intercept) that define the relationship between the input \n",
    "#features and the target variable. These parameters are learned from \n",
    "#the training data and are used to make predictions on new, unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46fc09e-88e2-41ff-85d6-17ebac2bff34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f60ccb4f-4a96-4023-a3a8-cb928d256993",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2. What is correlation?\n",
    "#What does negative correlation mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "378477e9-76ca-415b-a829-3be32da44e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation is a statistical measure that describes the relationship \n",
    "#between two or more variables. It quantifies the degree to which changes\n",
    "#in one variable are associated with changes in another variable.\n",
    "\n",
    "#Types of Correlation\n",
    "#1. Positive Correlation: A positive correlation exists when an increase\n",
    "#in one variable is associated with an increase in another variable.\n",
    "#For example, the relationship between height and weight in humans.\n",
    "#2. Negative Correlation: A negative correlation exists when an increase\n",
    "#in one variable is associated with a decrease in another variable. \n",
    "#For example, the relationship between temperature and snowfall in a region.\n",
    "#3. No Correlation: No correlation exists when there is no systematic \n",
    "#relationship between two variables.\n",
    "\n",
    "#Negative Correlation\n",
    "#A negative correlation indicates that as one variable increases, the other\n",
    "#variable tends to decrease. This relationship can be useful in machine \n",
    "#learning models, such as:\n",
    "\n",
    "#- Predicting stock prices: If two stocks have a negative correlation,\n",
    "#an increase in one stock's price may be associated with a decrease in\n",
    "#the other stock's price.\n",
    "#- Analyzing customer behavior: If there's a negative correlation between\n",
    "#the amount spent on advertising and customer complaints, increasing advertising\n",
    "#spend might lead to fewer complaints.\n",
    "\n",
    "#Correlation Coefficient\n",
    "#The correlation coefficient is a numerical value that measures the strength \n",
    "#and direction of the relationship between two variables. Common correlation \n",
    "#coefficients include:\n",
    "\n",
    "#- Pearson's r: Measures linear correlation between two continuous variables.\n",
    "#- Spearman's rho: Measures rank correlation between two variables.\n",
    "\n",
    "#The correlation coefficient ranges from -1 (perfect negative correlation) \n",
    "#to 1 (perfect positive correlation), with 0 indicating no correlation.\n",
    "\n",
    "#Importance of Correlation in Machine Learning\n",
    "#Understanding correlation is essential in machine learning because it helps:\n",
    "\n",
    "#- Identify relationships between variables\n",
    "#- Select relevant features for modeling\n",
    "#- Develop predictive models that capture underlying patterns in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87c4682-d653-485b-bfd9-34f22ffe7443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9291d07-a634-4422-9d08-1bbda86e34fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3. Define Machine Learning. What are the main components in Machine Learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2f5ff8-295f-4bab-9fba-e650c7201418",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Machine Learning Definition\n",
    "#Machine learning is a subset of artificial intelligence (AI) \n",
    "#that enables computers to learn from data and improve their\n",
    "#performance on a task without being explicitly programmed. \n",
    "#It involves training algorithms on data to make predictions,\n",
    "#classify objects, or make decisions.\n",
    "\n",
    "#Main Components of Machine Learning\n",
    "#The main components of machine learning are:\n",
    "\n",
    "#1. Data: The input to the machine learning algorithm, which can\n",
    "#be structured (e.g., tables, databases) or unstructured (e.g., text, images, audio).\n",
    "#2. Model: A mathematical representation of the relationships between \n",
    "#variables in the data. The model is trained on the data to make predictions\n",
    "#or decisions.\n",
    "#3. Algorithm: A set of instructions that defines how the model learns \n",
    "#from the data. Common machine learning algorithms include decision trees,\n",
    "#random forests, support vector machines, and neural networks.\n",
    "#4. Training: The process of adjusting the model's parameters to fit the data.\n",
    "#During training, the model learns to make predictions or decisions based on \n",
    "#the patterns in the data.\n",
    "#5. Evaluation: The process of assessing the performance of a trained \n",
    "#model on unseen data. Evaluation metrics help determine how well the model\n",
    "#generalizes to new data.\n",
    "\n",
    "#Key Aspects of Machine Learning\n",
    "#- Learning from data: Machine learning algorithms learn from data\n",
    "#without being explicitly programmed.\n",
    "#- Pattern recognition: Machine learning models recognize patterns in\n",
    "#data to make predictions or decisions.\n",
    "#- Improvement over time: Machine learning models can improve their\n",
    "#performance over time as they receive more data and feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff93b80b-8585-4d71-b38f-5cac7acf08a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4c2a97a5-dd01-4840-b28e-ea6a55f5f655",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4. How does loss value help in determining whether the model is good or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa448e9-17ac-4972-a3d1-277a329fe5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss Value in Machine Learning\n",
    "#The loss value, also known as the cost function or objective \n",
    "#function, is a measure of the difference between the model's \n",
    "#predictions and the actual true values. It quantifies the error \n",
    "#or loss incurred by the model during training or evaluation.\n",
    "\n",
    "#Role of Loss Value in Model Evaluation\n",
    "#The loss value plays a crucial role in determining whether a \n",
    "#model is good or not. Here's how:\n",
    "\n",
    "#1. Model Performance: A lower loss value indicates that the model\n",
    "#is performing well and making accurate predictions. Conversely, \n",
    "#a higher loss value suggests that the model is not performing well \n",
    "#and needs improvement.\n",
    "#2. Model Optimization: The loss value is used to optimize the model's\n",
    "#parameters during training. The goal is to minimize the loss value,\n",
    "#which means the model is learning to make better predictions.\n",
    "#3. Model Comparison: Loss values can be used to compare the performance\n",
    "#of different models. A model with a lower loss value is generally \n",
    "#considered better than one with a higher loss value.\n",
    "\n",
    "#Types of Loss Functions\n",
    "#Common loss functions used in machine learning include:\n",
    "\n",
    "#1. Mean Squared Error (MSE): Measures the average squared difference \n",
    "#between predicted and actual values.\n",
    "#2. Cross-Entropy Loss: Measures the difference between predicted \n",
    "#probabilities and actual labels.\n",
    "#3. Mean Absolute Error (MAE): Measures the average absolute \n",
    "#difference between predicted and actual values.\n",
    "\n",
    "#Interpreting Loss Values\n",
    "\n",
    "#1. Lower is better: A lower loss value generally indicates better\n",
    "#model performance.\n",
    "#2. Context-dependent: The interpretation of loss values depends on\n",
    "#the specific problem, data, and model.\n",
    "#3. Comparison to baseline: Compare the loss value to a baseline \n",
    "#model or a previously trained model to determine if the current model \n",
    "#is performing better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861cf598-4817-4eac-b7ac-ca3ad6c01faa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfe9d69-d779-468a-bdeb-55868b14df04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5. What are continuous and categorical variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85634cf7-234e-4560-ba91-59452216ea55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables in Machine Learning\n",
    "#In machine learning, variables can be broadly classified into \n",
    "#two types: continuous and categorical.\n",
    "\n",
    "#Continuous Variables\n",
    "#Continuous variables are numerical variables that can take on \n",
    "#any value within a given range or interval. These variables can be\n",
    "#measured with precision and can have any value, including decimals \n",
    "#and fractions. Examples of continuous variables include:\n",
    "\n",
    "#1. Height: A person's height can be measured in meters or feet and \n",
    "#can take on any value within a range (e.g., 1.5 meters to 2.5 meters).\n",
    "#2. Temperature: Temperature can be measured in degrees Celsius or \n",
    "#Fahrenheit and can take on any value within a range (e.g., -20°C to 50°C).\n",
    "#3. Age: Age can be measured in years, months, or days and can take on \n",
    "#any value within a range (e.g., 0 to 100 years).\n",
    "\n",
    "#Categorical Variables\n",
    "#Categorical variables, also known as nominal or ordinal variables,\n",
    "#are variables that take on discrete values or categories. These variables\n",
    "#represent different classes or groups, and the values are often labels or\n",
    "#names rather than numerical values. Examples of categorical variables include:\n",
    "\n",
    "#1. Color: A color can be categorized as red, blue, green, etc.\n",
    "#2. Gender: A person's gender can be categorized as male, female, or other.\n",
    "#3. Product category: A product can be categorized as electronics,\n",
    "#clothing, or food.\n",
    "\n",
    "#Key Differences\n",
    "#The key differences between continuous and categorical variables are:\n",
    "\n",
    "#1. Numerical vs. categorical values: Continuous variables have numerical\n",
    "#values, while categorical variables have discrete values or labels.\n",
    "#2. Measurement precision: Continuous variables can be measured with \n",
    "#precision, while categorical variables are often subjective and depend \n",
    "#on classification.\n",
    "#3. Analysis and modeling: Continuous variables are often analyzed using \n",
    "#statistical methods like regression, while categorical variables are \n",
    "#often analyzed using classification models like logistic regression or\n",
    "#decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1520b36-816b-4e21-a1fe-eab3dd29c6b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "da29c334-2baa-4808-9c01-275ae21099e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6. How do we handle categorical variables in Machine Learning?\n",
    "#What are the common techniques?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d2e2df-071b-44ac-bd9c-11fd17f236c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling Categorical Variables in Machine Learning\n",
    "#Categorical variables are variables that take on discrete values\n",
    "#or categories. To use these variables in machine learning models,\n",
    "#we need to convert them into numerical representations that the\n",
    "#models can understand. Here are some common techniques for handling\n",
    "#categorical variables:\n",
    "\n",
    "#1. Label Encoding\n",
    "#Label encoding is a technique where each category is assigned a unique\n",
    "#integer value. For example, if we have a categorical variable \"color\" with \n",
    "#categories \"red\", \"green\", and \"blue\", we can assign the values 0, 1, and 2 \n",
    "#to each category, respectively.\n",
    "\n",
    "#2. One-Hot Encoding\n",
    "#One-hot encoding is a technique where each category is represented as a\n",
    "#binary vector. For example, if we have a categorical variable \"color\" with\n",
    "#categories \"red\", \"green\", and \"blue\", we can represent each category as a \n",
    "#binary vector:\n",
    "\n",
    "#- Red: [1, 0, 0]\n",
    "#- Green: [0, 1, 0]\n",
    "#- Blue: [0, 0, 1]\n",
    "\n",
    "#3. Ordinal Encoding\n",
    "#Ordinal encoding is a technique where each category is assigned a numerical \n",
    "#value based on its order or ranking. For example, if we have a categorical\n",
    "#variable \"size\" with categories \"small\", \"medium\", and \"large\", we can assign\n",
    "#the values 1, 2, and 3 to each category, respectively.\n",
    "\n",
    "#4. Binary Encoding\n",
    "#Binary encoding is a technique where each category is represented as a \n",
    "#binary code. For example, if we have a categorical variable \"color\" with \n",
    "#categories \"red\", \"green\", and \"blue\", we can represent each category as\n",
    "#a binary code:\n",
    "\n",
    "#- Red: 00\n",
    "#- Green: 01\n",
    "#- Blue: 10\n",
    "\n",
    "#5. Hashing\n",
    "#Hashing is a technique where each category is mapped to a numerical value \n",
    "#using a hash function. This technique is useful when dealing with \n",
    "#high-cardinality categorical variables.\n",
    "\n",
    "#Common Considerations\n",
    "\n",
    "#1. Cardinality: Be mindful of the number of categories in your \n",
    "#variable. High-cardinality variables can lead to the curse of dimensionality.\n",
    "#2. Encoding technique: Choose an encoding technique that suits \n",
    "#your problem and data. For example, one-hot encoding can lead \n",
    "#to sparse data, while label encoding can imply ordinal relationships.\n",
    "#3. Model selection: Some machine learning models can handle\n",
    "#categorical variables directly, while others require numerical\n",
    "#representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718953d2-ab3d-4ced-8eab-53e18621dc12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30dca5d-a3ae-4957-bd28-68c3000b8f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7. What do you mean by training and testing a dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ba634f-3ca6-40cc-8ed7-bb68da71f416",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training and Testing a Dataset\n",
    "#In machine learning, a dataset is typically split into two parts: \n",
    "#a training set and a testing set. This division is crucial for evaluating\n",
    "#the performance of a model and ensuring that it generalizes well to \n",
    "#unseen data.\n",
    "\n",
    "#Training a Dataset\n",
    "#Training a dataset involves using a machine learning algorithm to learn\n",
    "#patterns and relationships within the data. The goal is to adjust the \n",
    "#model's parameters to minimize the difference between the model's predictions\n",
    "#and the actual outcomes. During training, the model learns to make predictions \n",
    "#or decisions based on the patterns in the data.\n",
    "\n",
    "#Testing a Dataset\n",
    "#Testing a dataset involves evaluating the performance of a \n",
    "#trained model on unseen data. The testing set is used to assess \n",
    "#how well the model generalizes to new, unseen data. This step is\n",
    "#crucial for determining the model's accuracy, precision, recall,\n",
    "#and other performance metrics.\n",
    "\n",
    "#Key Aspects of Training and Testing\n",
    "#1. Data Split: The dataset is typically split into training and \n",
    "#testing sets using techniques like random sampling or stratified sampling.\n",
    "#2. Model Evaluation: The performance of the model is evaluated on \n",
    "#the testing set using metrics like accuracy, precision, recall, \n",
    "#F1-score, mean squared error, or mean absolute error.\n",
    "#3. Model Selection: The performance of different models can be compared\n",
    "#using the testing set, allowing for model selection and hyperparameter tuning.\n",
    "#4. Overfitting and Underfitting: The testing set helps identify \n",
    "#overfitting (when a model is too complex and performs well on the training \n",
    "#set but poorly on the testing set) and underfitting (when a model is too \n",
    "#simple and fails to capture the underlying patterns in the data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206378a4-10eb-4768-acfd-4339bea1a332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcb70ed-39d5-48ad-a915-fe4bda0542e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8.What is sklearn.preprocessing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e296694e-5190-461b-9932-2d77450b0603",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sklearn.Preprocessing\n",
    "#Sklearn.preprocessing is a module in the scikit-learn library,\n",
    "#a popular machine learning library in Python. This module provides \n",
    "#various tools and techniques for preprocessing data, which is a \n",
    "#crucial step in machine learning pipelines.\n",
    "\n",
    "#Purpose of Preprocessing\n",
    "#The primary purpose of preprocessing is to transform and \n",
    "#prepare the data for modeling. This includes:\n",
    "\n",
    "#1. Data Cleaning: Handling missing values, outliers, and \n",
    "#inconsistencies in the data.\n",
    "#2. Data Transformation: Scaling, normalizing, or encoding\n",
    "#data to make it suitable for modeling.\n",
    "#3. Feature Engineering: Creating new features or modifying\n",
    "#existing ones to improve model performance.\n",
    "\n",
    "#Key Features of Sklearn.Preprocessing\n",
    "#Some key features of the sklearn.preprocessing module include:\n",
    "\n",
    "#1. Scaling: Techniques like StandardScaler and MinMaxScaler\n",
    "#help scale numerical features to a common range.\n",
    "#2. Normalization: Techniques like Normalizer help normalize \n",
    "#data to have a length of 1.\n",
    "#3. Encoding: Techniques like LabelEncoder and OneHotEncoder \n",
    "#help encode categorical variables into numerical representations.\n",
    "#4. Imputation: Techniques like SimpleImputer help handle missing\n",
    "#values in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c486e5b-9a6d-4219-a17d-6d22396f3429",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7a788616-4916-4049-abde-b8e00b113e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q9. What is a Test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09df7cad-fdc0-493a-a5d7-9fe98b19a898",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Set\n",
    "#A test set, also known as a holdout set or evaluation set, is a \n",
    "#portion of a dataset that is used to evaluate the performance of\n",
    "#a machine learning model. The test set is a representative sample\n",
    "#of the data that is not used during the training process, allowing \n",
    "#for an unbiased assessment of the model's performance.\n",
    "\n",
    "#Purpose of a Test Set\n",
    "#The primary purpose of a test set is to:\n",
    "\n",
    "#1. Evaluate Model Performance: Assess the accuracy, precision,\n",
    "#recall, and other performance metrics of a trained model.\n",
    "#2. Estimate Generalization: Determine how well the model \n",
    "#generalizes to new, unseen data.\n",
    "#3. Compare Models: Compare the performance of different\n",
    "#models or algorithms.\n",
    "\n",
    "#Characteristics of a Test Set\n",
    "#A good test set should have the following characteristics:\n",
    "\n",
    "#1. Representative: The test set should be representative of the data\n",
    "#distribution and characteristics.\n",
    "#2. Unseen Data: The test set should not be used during the training\n",
    "#process to ensure an unbiased assessment.\n",
    "#3. Sufficient Size: The test set should be large enough to provide \n",
    "#reliable estimates of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82eeade6-ade4-49b6-915f-efad82b5a4d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3fb9bd71-a532-49de-8b67-587dc718a73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q10. How do we split data for model fitting (training and testing) \n",
    "#in Python?\n",
    "#How do you approach a Machine Learning problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ed9cb54b-08c0-4b5f-a59c-6d86863b2d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting Data for Model Fitting in Python\n",
    "#Splitting data into training and testing sets is a crucial step \n",
    "#in machine learning. In Python, we can use the train_test_split\n",
    "#function from the scikit-learn library to achieve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1a1c3af7-335d-474e-a3fe-f0c276d4d0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 640\n",
      "Testing set size: 160\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>318</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>405</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>525</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>VenusaurMega Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>625</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>123</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Charmander</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>309</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #                   Name Type 1  Type 2  Total  HP  Attack  Defense  \\\n",
       "0  1              Bulbasaur  Grass  Poison    318  45      49       49   \n",
       "1  2                Ivysaur  Grass  Poison    405  60      62       63   \n",
       "2  3               Venusaur  Grass  Poison    525  80      82       83   \n",
       "3  3  VenusaurMega Venusaur  Grass  Poison    625  80     100      123   \n",
       "4  4             Charmander   Fire     NaN    309  39      52       43   \n",
       "\n",
       "   Sp. Atk  Sp. Def  Speed  Generation  Legendary  \n",
       "0       65       65     45           1      False  \n",
       "1       80       80     60           1      False  \n",
       "2      100      100     80           1      False  \n",
       "3      122      120     80           1      False  \n",
       "4       60       50     65           1      False  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('pokemon.csv')\n",
    "X = df.drop('Speed', axis=1)\n",
    "y = df['Speed']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Training set size:\", len(X_train))\n",
    "print(\"Testing set size:\", len(X_test))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ce6539f5-344b-452e-a37b-ac3848d3f807",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explanation\n",
    "#1. Import necessary libraries: We import train_test_split from \n",
    "#scikit-learn and pandas for data manipulation.\n",
    "#2. Load the dataset: Load your dataset into a pandas DataFrame.\n",
    "#3. Split the data: Split the data into features (X) and target (y).\n",
    "#4. *Use train_test_split*: Split the data into training and \n",
    "#testing sets using train_test_split.\n",
    "#5. *test_size parameter*: Specify the proportion of data for \n",
    "#the test set (e.g., 0.2 for 20%).\n",
    "#6. *random_state parameter*: Set a seed for reproducibility.\n",
    "\n",
    "#Approaching a Machine Learning Problem\n",
    "\n",
    "#1. Problem Definition\n",
    "#- Define the problem: Clearly articulate the problem \n",
    "#you're trying to solve.\n",
    "#- Identify the goal: Determine what you want to achieve with\n",
    "#your machine learning model.\n",
    "\n",
    "#2. Data Collection\n",
    "#- Collect relevant data: Gather data that's relevant to your problem.\n",
    "#- Ensure data quality: Verify that your data is accurate, complete, and consistent.\n",
    "\n",
    "#3. Data Preprocessing\n",
    "#- Clean the data: Handle missing values, outliers, and inconsistencies.\n",
    "#- Transform the data: Scale or normalize the data if necessary.\n",
    "\n",
    "#4. Exploratory Data Analysis (EDA)\n",
    "#- Understand the data: Perform EDA to understand the data distribution\n",
    "#and relationships.\n",
    "#- Visualize the data: Use plots and charts to visualize the data.\n",
    "\n",
    "#5. Feature Engineering\n",
    "#- Extract relevant features: Identify the most relevant features\n",
    "#for your model.\n",
    "#- Create new features: Engineer new features if necessary.\n",
    "\n",
    "#6. Model Selection\n",
    "#- Choose a suitable algorithm: Select a machine learning algorithm \n",
    "#that's suitable for your problem.\n",
    "#- Consider factors: Consider factors like data size, complexity, \n",
    "#and performance metrics.\n",
    "\n",
    "#7. Model Training\n",
    "#- Train the model: Train your model using the training data.\n",
    "#- Tune hyperparameters: Tune hyperparameters if necessary.\n",
    "\n",
    "#8. Model Evaluation\n",
    "#- Evaluate the model: Evaluate your model using the testing data.\n",
    "#- Use performance metrics: Use metrics like accuracy, precision, \n",
    "#recall, F1-score, mean squared error, or mean absolute error.\n",
    "\n",
    "#9. Model Deployment\n",
    "#- Deploy the model: Deploy your model in a production-ready \n",
    "#environment.\n",
    "#- Monitor performance: Monitor your model's performance and \n",
    "#retrain if necessary.\n",
    "\n",
    "#10. Iteration and Improvement\n",
    "#- Iterate and refine: Continuously iterate and refine your \n",
    "#model to improve performance.\n",
    "#- Stay up-to-date: Stay up-to-date with the latest techniques\n",
    "#and advancements in machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff54734-6f1f-4309-9386-994ce07edaf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "eee18e65-cfc1-4e92-bbf4-c984a8d849ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q11. Why do we have to perform EDA before fitting a model to the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc861a6-3b8a-4fac-b248-31f6af9278dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exploratory Data Analysis (EDA)\n",
    "#Performing EDA before fitting a model to the data is a crucial\n",
    "#step in the machine learning pipeline. EDA helps to understand \n",
    "#the underlying structure of the data, identify patterns and \n",
    "#relationships, and detect potential issues that may impact \n",
    "#model performance.\n",
    "\n",
    "#Importance of EDA\n",
    "#1. Understanding Data Distribution: EDA helps to understand the \n",
    "#distribution of the data, including measures of central tendency\n",
    "#and variability.\n",
    "#2. Identifying Relationships: EDA reveals relationships between\n",
    "#variables, including correlations and dependencies.\n",
    "#3. Detecting Outliers and Anomalies: EDA helps to identify outliers \n",
    "#and anomalies that may impact model performance.\n",
    "#4. Informing Feature Engineering: EDA informs feature selection and \n",
    "#creation by identifying the most relevant features for the model.\n",
    "#5. Guiding Model Selection: EDA can guide model selection by revealing\n",
    "#the nature of the data and the relationships between variables.\n",
    "\n",
    "#Benefits of EDA\n",
    "#1. Improved Model Performance: EDA can lead to improved model\n",
    "#performance by identifying potential issues and informing \n",
    "#data-driven decisions.\n",
    "#2. Reduced Risk of Overfitting: EDA can help to reduce the \n",
    "#risk of overfitting by identifying potential issues with the data.\n",
    "#3. Increased Confidence: EDA can increase confidence in the model\n",
    "#by providing a deeper understanding of the data and the\n",
    "#relationships between variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506100df-1108-4202-8a45-1ae7f350add6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f8e26e3a-57bc-419c-84cb-ac96ff05b290",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q12.What is correlation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "367fc444-6a70-4e6a-9814-30e68636ec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation is a statistical measure that describes the relationship \n",
    "#between two or more variables. It quantifies the degree to which \n",
    "#changes in one variable are associated with changes in another variable.\n",
    "\n",
    "#Types of Correlation\n",
    "#1. Positive Correlation: A positive correlation exists \n",
    "#when an increase in one variable is associated with an \n",
    "#increase in another variable. For example, the relationship \n",
    "#between height and weight in humans.\n",
    "#2. Negative Correlation: A negative correlation exists\n",
    "#when an increase in one variable is associated with a decrease \n",
    "#in another variable. For example, the relationship between \n",
    "#temperature and snowfall in a region.\n",
    "#3. No Correlation: No correlation exists when there is no\n",
    "#systematic relationship between two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724a0b97-ce6f-451a-a1c1-0553db5079dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a70c2103-fdee-41dd-9e95-0aa9fe277e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q13. What does negative correlation mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6c669f1d-e7f4-403b-84a3-c3e53b853086",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Negative Correlation\n",
    "#A negative correlation indicates that as one variable increases,\n",
    "#the other variable tends to decrease. This relationship can be \n",
    "#useful in machine learning models, such as:\n",
    "\n",
    "#- Predicting stock prices: If two stocks have a negative correlation,\n",
    "#an increase in one stock's price may be associated with a decrease\n",
    "#in the other stock's price.\n",
    "#- Analyzing customer behavior: If there's a negative correlation\n",
    "#between the amount spent on advertising and customer complaints,\n",
    "#increasing advertising spend might lead to fewer complaints.\n",
    "\n",
    "#Correlation Coefficient\n",
    "#The correlation coefficient is a numerical value that measures\n",
    "#the strength and direction of the relationship between two variables.\n",
    "#Common correlation coefficients include:\n",
    "\n",
    "#- Pearson's r: Measures linear correlation between two continuous variables.\n",
    "#- Spearman's rho: Measures rank correlation between two variables.\n",
    "\n",
    "#The correlation coefficient ranges from -1 (perfect negative correlation)\n",
    "#to 1 (perfect positive correlation), with 0 indicating no correlation.\n",
    "\n",
    "#Importance of Correlation in Machine Learning\n",
    "#Understanding correlation is essential in machine learning because it helps:\n",
    "\n",
    "#- Identify relationships between variables\n",
    "#- Select relevant features for modeling\n",
    "#- Develop predictive models that capture underlying patterns in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb8bff0-7bbe-4585-a1ed-c402dbad884b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "12e7f4f8-5e89-451e-bee9-491caa8798e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q14. How can you find correlation between variables in Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f51e621f-0f7f-416d-84d5-e8276bebef0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding Correlation between Variables in Python\n",
    "#Correlation analysis is a statistical technique used to \n",
    "#measure the relationship between two or more variables.\n",
    "#In Python, we can use the corr() function from the pandas\n",
    "#library or the pearsonr() function from the scipy library\n",
    "#to calculate the correlation between variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e4ab181b-32b0-4533-846c-4c741f197c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          A         B         C\n",
      "A  1.000000  0.972272  0.993884\n",
      "B  0.972272  1.000000  0.985847\n",
      "C  0.993884  0.985847  1.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    'A': [1,2,3,4,5],\n",
    "    'B': [2,3,5,7,11],\n",
    "    'C': [3,4,6,8,10]\n",
    "})\n",
    "corr_matrix = df.corr()\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989c89a8-ef0b-4721-94b4-cec8f22b1790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9c2d9fed-85ce-4ff9-86b3-9e946e817b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interpretation of Results\n",
    "#- Correlation Coefficient: A value between -1 and 1 that measures\n",
    "#the strength and direction of the linear relationship between\n",
    "#two variables.\n",
    "#- P-value: A value that indicates the probability of observing\n",
    "#the correlation coefficient under the null hypothesis of no correlation.\n",
    "\n",
    "#Types of Correlation Coefficients\n",
    "#1. Pearson Correlation Coefficient: Measures linear relationships\n",
    "#between continuous variables.\n",
    "#2. Spearman Correlation Coefficient: Measures monotonic relationships\n",
    "#between variables.\n",
    "#3. Kendall Correlation Coefficient: Measures ordinal relationships\n",
    "#between variables.\n",
    "\n",
    "#Applications of Correlation Analysis\n",
    "#1. Feature Selection: Correlation analysis can be used to select \n",
    "#features that are highly correlated with the target variable.\n",
    "#2. Data Preprocessing: Correlation analysis can be used to identify\n",
    "#and handle multicollinearity in the data.\n",
    "#3. Predictive Modeling: Correlation analysis can be used to identify \n",
    "#relationships between variables that can be used to build predictive models.\n",
    "\n",
    "#By using correlation analysis, we can gain insights into the relationships\n",
    "#between variables and make informed decisions about feature selection, \n",
    "#data preprocessing, and predictive modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f821c56-e28c-4cc5-ab38-efca07207831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0106f3af-8095-46ec-bed1-fddcfdb36929",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q15. What is causation? Explain difference between correlation and \n",
    "#causation with an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859aba80-1732-47df-8016-b10cb15260d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Causation\n",
    "#Causation refers to a relationship between two variables where one \n",
    "#variable (the cause) directly affects the other variable (the effect). \n",
    "#In other words, causation implies that the occurrence of one event is\n",
    "#the result of the occurrence of another event.\n",
    "\n",
    "#Correlation vs. Causation\n",
    "#Correlation and causation are often confused with each other, \n",
    "#but they are distinct concepts. Correlation refers to a statistical\n",
    "#relationship between two variables, whereas causation implies a \n",
    "#cause-and-effect relationship.\n",
    "\n",
    "#Example: Ice Cream Sales and Shark Attacks\n",
    "#Suppose we analyze data on ice cream sales and shark attacks in \n",
    "#a coastal town. We find a strong positive correlation between the \n",
    "#two variables, meaning that on days when ice cream sales are high,\n",
    "#shark attacks are also more likely to occur.\n",
    "\n",
    "#Correlation Does Not Imply Causation\n",
    "#However, it would be incorrect to conclude that eating ice cream causes \n",
    "#shark attacks. Instead, the underlying cause of both variables is likely\n",
    "#the warm weather, which leads to more people swimming in the ocean \n",
    "#(increasing the risk of shark attacks) and buying ice cream to cool off.\n",
    "\n",
    "#Causation vs. Correlation\n",
    "#- Causation: Warm weather → More people swim in the ocean → \n",
    "#Increased risk of shark attacks\n",
    "#- Correlation: Ice cream sales and shark attacks are correlated, \n",
    "#but there is no direct causal relationship between them.\n",
    "\n",
    "#Key Takeaways\n",
    "#1. Correlation is not causation: A statistical relationship between\n",
    "#two variables does not necessarily imply a cause-and-effect relationship.\n",
    "#2. Look for underlying causes: When analyzing correlations, it's essential\n",
    "#to consider potential underlying causes that may be driving the relationship.\n",
    "#3. Establishing causation: To establish causation, we need to demonstrate \n",
    "#a clear cause-and-effect relationship, often through experimentation or\n",
    "#careful analysis of observational data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7905bc-1073-4f03-8b16-695dae825cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q16. What is an Optimizer? What are different types of optimizers? \n",
    "#Explain each with an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa50a09-0b26-4c25-b5bd-98ad7f0e2e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizers in Machine Learning\n",
    "#An optimizer is a crucial component of machine learning algorithms \n",
    "#that adjusts the model's parameters to minimize the loss function.\n",
    "#The goal of an optimizer is to find the optimal values of the\n",
    "#model's parameters that result in the best performance on a given task.\n",
    "\n",
    "#Types of Optimizers\n",
    "#There are several types of optimizers used in machine learning, \n",
    "#each with its strengths and weaknesses. Here are some of the most\n",
    "#commonly used optimizers:\n",
    "\n",
    "#1. Gradient Descent (GD)\n",
    "#Gradient Descent is a first-order optimization algorithm that \n",
    "#iteratively updates the model's parameters in the direction of\n",
    "#the negative gradient of the loss function.\n",
    "\n",
    "#Example: Suppose we want to minimize the loss function \n",
    "#L(w) = (w - 2)^2, where w is the model's parameter. Using GD,\n",
    "#we would update w as follows: w_new = w_old - learning_rate * 2 * (w_old - 2).\n",
    "\n",
    "#2. Stochastic Gradient Descent (SGD)\n",
    "#Stochastic Gradient Descent is a variant of GD that uses a single\n",
    "#example from the training dataset to compute the gradient of the \n",
    "#loss function at each iteration.\n",
    "\n",
    "#Example: Suppose we have a dataset of images, and we want to train\n",
    "#a model to classify them. Using SGD, we would update the model's\n",
    "#parameters after each image is processed.\n",
    "\n",
    "#3. Mini-Batch Gradient Descent (MBGD)\n",
    "#Mini-Batch Gradient Descent is a variant of GD that uses a \n",
    "#small batch of examples from the training dataset to compute \n",
    "#the gradient of the loss function at each iteration.\n",
    "\n",
    "#Example: Suppose we have a dataset of 1000 images, and we want to \n",
    "#train a model to classify them. Using MBGD with a batch size of 32,\n",
    "#we would update the model's parameters after every 32 images are processed.\n",
    "\n",
    "#4. Momentum Optimizer\n",
    "#Momentum Optimizer is a variant of GD that adds a momentum term to \n",
    "#the update rule, which helps to escape local minima and converge faster.\n",
    "\n",
    "#Example: Suppose we want to minimize the loss function\n",
    "#L(w) = (w - 2)^2, where w is the model's parameter. Using \n",
    "#Momentum Optimizer, we would update w as follows: \n",
    "#v_new = momentum * v_old + learning_rate * 2 * (w_old - 2), \n",
    "#w_new = w_old - v_new.\n",
    "\n",
    "#5. Nesterov Accelerated Gradient (NAG)\n",
    "#Nesterov Accelerated Gradient is a variant of Momentum Optimizer\n",
    "#that uses a different update rule to compute the momentum term.\n",
    "\n",
    "#Example: Suppose we want to minimize the loss function \n",
    "#L(w) = (w - 2)^2, where w is the model's parameter. Using NAG,\n",
    "#we would update w as follows: v_new = momentum * v_old + \n",
    "#learning_rate * 2 * (w_old + momentum * v_old - 2), w_new = w_old - v_new.\n",
    "\n",
    "#6. RMSProp\n",
    "#RMSProp is an optimizer that uses a different learning rate for \n",
    "#each parameter, which is adjusted based on the magnitude of the \n",
    "#gradient.\n",
    "\n",
    "#Example: Suppose we want to minimize the loss function \n",
    "#L(w) = (w - 2)^2, where w is the model's parameter. Using RMSProp,\n",
    "#we would update w as follows: cache_new = decay_rate * cache_old + \n",
    "#(1 - decay_rate) * (2 * (w_old - 2))^2, w_new = w_old - learning_rate\n",
    "#* 2 * (w_old - 2) / sqrt(cache_new + epsilon).\n",
    "\n",
    "#7. Adam Optimizer\n",
    "#Adam Optimizer is a popular optimizer that combines the benefits of \n",
    "#RMSProp and Momentum Optimizer.\n",
    "\n",
    "#Example: Suppose we want to minimize the loss function L(w) = (w - 2)^2,\n",
    "#where w is the model's parameter. Using Adam Optimizer, we would update\n",
    "#was follows: m_new = beta1 * m_old + (1 - beta1) * 2 * (w_old - 2),\n",
    "#v_new = beta2 * v_old + (1 - beta2) * (2 * (w_old - 2))^2, \n",
    "#w_new = w_old - learning_rate * m_new / sqrt(v_new + epsilon).\n",
    "\n",
    "#Each optimizer has its strengths and weaknesses, and the choice of\n",
    "#optimizer depends on the specific problem and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d13eb5-e605-4a79-91ef-9163bacf5c5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "525bce02-8960-4225-8f76-023ece0b0cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q17.What is sklearn.linear_model ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748e7717-2f37-48ec-8388-e612702fb86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn.linear_model\n",
    "#sklearn.linear_model is a module in the scikit-learn library \n",
    "#that provides a wide range of linear models for regression, \n",
    "#classification, and other tasks. These models are based on \n",
    "#linear relationships between the features and the target variable.\n",
    "\n",
    "#Key Features of sklearn.linear_model\n",
    "#1. Linear Regression: LinearRegression is a class in sklearn.\n",
    "#linear_model that implements ordinary least squares (OLS) \n",
    "#linear regression.\n",
    "#2. Ridge Regression: Ridge is a class in sklearn.linear_model that\n",
    "#implements ridge regression, which is a regularized version of \n",
    "#linear regression.\n",
    "#3. Lasso Regression: Lasso is a class in sklearn.linear_model\n",
    "#that implements lasso regression, which is a regularized version\n",
    "#of linear regression that uses L1 regularization.\n",
    "#4. Elastic Net: ElasticNet is a class in sklearn.linear_model\n",
    "#that implements elastic net regression, which is a regularized\n",
    "#version of linear regression that combines L1 and L2 regularization.\n",
    "#5. Logistic Regression: LogisticRegression is a class in sklearn.\n",
    "#linear_model that implements logistic regression for binary \n",
    "#classification problems.\n",
    "\n",
    "#Applications of sklearn.linear_model\n",
    "#1. Regression Tasks: sklearn.linear_model can be used for \n",
    "#regression tasks, such as predicting continuous outcomes like\n",
    "#house prices or stock prices.\n",
    "#2. Classification Tasks: sklearn.linear_model can be used for\n",
    "#classification tasks, such as binary classification problems\n",
    "#like spam vs. non-spam emails.\n",
    "#3. Feature Selection: sklearn.linear_model can be used for feature \n",
    "#selection, as some models like Lasso and Elastic Net can set \n",
    "#coefficients to zero, effectively selecting a subset of features.\n",
    "\n",
    "#Advantages of sklearn.linear_model\n",
    "#1. Interpretability: Linear models are highly interpretable, \n",
    "#as the coefficients represent the change in the outcome variable \n",
    "#for a one-unit change in the feature.\n",
    "#2. Efficiency: Linear models are computationally efficient and \n",
    "#can handle large datasets.\n",
    "#3. Flexibility: sklearn.linear_model provides a range of models \n",
    "#that can be used for different tasks and datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05eea157-2505-4117-a53c-f2ef8382438e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 2900.1936284934804\n",
      "R2 Score: 0.4526027629719196\n"
     ]
    }
   ],
   "source": [
    "#Example\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "diabetes = load_diabetes()\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R2 Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d6b333-b72d-4294-8780-8105f94164c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02e7408a-a307-41dc-bcdb-bcad95eab8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q18.What does model.fit() do? What arguments must be given?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5524d7ef-33cd-4195-af75-207e5787cfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Fitting\n",
    "#model.fit() is a method in scikit-learn that trains a machine \n",
    "#learning model on a given dataset. It adjusts the model's \n",
    "#parameters to minimize the loss function and optimize the \n",
    "#model's performance.\n",
    "\n",
    "#1. Model Initialization: The model is initialized with the\n",
    "#given parameters.\n",
    "#2. Data Validation: The input data is validated to ensure it\n",
    "#meets the model's requirements.\n",
    "#3. Model Training: The model is trained on the training data\n",
    "#using an optimization algorithm.\n",
    "#4. Parameter Update: The model's parameters are updated based\n",
    "#on the training data and the optimization algorithm.\n",
    "\n",
    "#Arguments for model.fit()\n",
    "#The model.fit() method typically requires the following arguments:\n",
    "\n",
    "#1. X: The feature matrix, which is a 2D array-like object\n",
    "#containing the input data.\n",
    "#2. y: The target vector, which is a 1D array-like object\n",
    "#containing the output data.\n",
    "\n",
    "#Optional arguments may include:\n",
    "\n",
    "#1. sample_weight: An array-like object containing the weights \n",
    "#for each sample in the training data.\n",
    "\n",
    "#Example Usage\n",
    "#Here's an example of using model.fit() with a Linear \n",
    "#Regression model:\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "diabetes = load_diabetes()\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#In this example, we create a Linear Regression model and fit it to\n",
    "#the training data using model.fit(X_train, y_train). The model learns\n",
    "#the relationships between the input features and the target variable,\n",
    "#and we can use it to make predictions on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a811845f-30a3-493c-bb00-a5a4af14cb99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "diabetes = load_diabetes()\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "597e6d3e-367d-4b04-b36e-2e554e7191f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this example, we create a Linear Regression model and fit it to \n",
    "#the training data using model.fit(X_train, y_train). The model learns\n",
    "#the relationships between the input features and the target variable,\n",
    "#and we can use it to make predictions on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1f810e-6864-42df-8f9f-dc8ac916954a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b0e7a2-f22d-4999-b407-807e8ab355b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q19. What does model.predict() do? What arguments must be given?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75e8d2d4-0a66-41e7-beaf-5221d3b5321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Prediction\n",
    "#model.predict() is a method in scikit-learn that uses a trained\n",
    "#machine learning model to make predictions on new, unseen data.\n",
    "\n",
    "#1. Input Validation: The input data is validated to ensure it\n",
    "#meets the model's requirements.\n",
    "#2. Prediction: The model uses its learned parameters to make\n",
    "#predictions on the input data.\n",
    "#3. Output Generation: The predicted values are generated and returned.\n",
    "\n",
    "#Arguments for model.predict()\n",
    "#The model.predict() method typically requires the following argument:\n",
    "\n",
    "#1. X: The feature matrix, which is a 2D array-like object containing \n",
    "#the input data to make predictions on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3c9bb3e6-c984-4542-889c-3647d447ce0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Values:\n",
      "[139.5475584  179.51720835 134.03875572 291.41702925 123.78965872\n",
      "  92.1723465  258.23238899 181.33732057  90.22411311 108.63375858\n",
      "  94.13865744 168.43486358  53.5047888  206.63081659 100.12925869\n",
      " 130.66657085 219.53071499 250.7803234  196.3688346  218.57511815\n",
      " 207.35050182  88.48340941  70.43285917 188.95914235 154.8868162\n",
      " 159.36170122 188.31263363 180.39094033  47.99046561 108.97453871\n",
      " 174.77897633  86.36406656 132.95761215 184.53819483 173.83220911\n",
      " 190.35858492 124.4156176  119.65110656 147.95168682  59.05405241\n",
      "  71.62331856 107.68284704 165.45365458 155.00975931 171.04799096\n",
      "  61.45761356  71.66672581 114.96732206  51.57975523 167.57599528\n",
      " 152.52291955  62.95568515 103.49741722 109.20751489 175.64118426\n",
      " 154.60296242  94.41704366 210.74209145 120.2566205   77.61585399\n",
      " 187.93203995 206.49337474 140.63167076 105.59678023 130.70432536\n",
      " 202.18534537 171.13039501 164.91423047 124.72472569 144.81030894\n",
      " 181.99635452 199.41369642 234.21436188 145.95665512  79.86703276\n",
      " 157.36941275 192.74412541 208.89814032 158.58722555 206.02195855\n",
      " 107.47971675 140.93598906  54.82129332  55.92573195 115.01180018\n",
      "  78.95584188  81.56087285  54.37997256 166.2543518 ]\n",
      "First 5 Predicted Values:\n",
      "[139.5475584  179.51720835 134.03875572 291.41702925 123.78965872]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "diabetes = load_diabetes()\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Predicted Values:\")\n",
    "print(y_pred)\n",
    "\n",
    "print(\"First 5 Predicted Values:\")\n",
    "print(y_pred[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d076db8-588e-4089-ab81-07dd9fcf3492",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this example, we train a Linear Regression model on the training \n",
    "#data and use model.predict(X_test) to make predictions on the \n",
    "#testing data. The predicted values are stored in y_pred.\n",
    "\n",
    "#Key Points\n",
    "#- model.predict() can only be used after the model has been trained\n",
    "#using model.fit().\n",
    "#- The input data X must have the same shape and features as the \n",
    "#training data used to fit the model.\n",
    "#- The predicted values are typically returned as a 1D array-like \n",
    "#object, where each element corresponds to the predicted value for\n",
    "#a sample in the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abe0ce8-e62f-4296-a3ef-b50a4ced6483",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0572cf7-34d6-4976-b10c-4c10cca3e0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q20. What are continuous and categorical variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd358236-d582-4160-8b07-6417e28db06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables in Data Analysis\n",
    "#In data analysis, variables can be broadly classified into two\n",
    "#types: continuous and categorical.\n",
    "\n",
    "#Continuous Variables\n",
    "#Continuous variables are numerical variables that can take any value \n",
    "#within a given range or interval. They can be measured with a high\n",
    "#degree of precision and can have any value, including fractions and decimals.\n",
    "\n",
    "#Examples of Continuous Variables:\n",
    "\n",
    "#- Age\n",
    "#- Height\n",
    "#- Weight\n",
    "#- Temperature\n",
    "#- Time\n",
    "\n",
    "#Categorical Variables\n",
    "#Categorical variables, also known as nominal or ordinal variables,\n",
    "#are variables that take on distinct categories or labels. These \n",
    "#variables are often non-numerical and represent different groups\n",
    "#or classes.\n",
    "\n",
    "#Examples of Categorical Variables:\n",
    "\n",
    "#- Gender (Male/Female/Other)\n",
    "#- Color (Red/Blue/Green)\n",
    "#- Product category (Electronics/Fashion/Home Goods)\n",
    "#- Education level (High School/College/University)\n",
    "\n",
    "#Key Differences\n",
    "#- Measurement Scale: Continuous variables are measured on a continuous scale, while categorical variables are measured on a nominal or ordinal scale.\n",
    "#- Values: Continuous variables can take any value within a range, while categorical variables take on distinct categories or labels.\n",
    "#- Analysis: Continuous variables are often analyzed using statistical methods such as regression and correlation, while categorical variables are often analyzed using methods such as chi-squared tests and logistic regression.\n",
    "\n",
    "#Importance of Distinguishing Between Continuous and Categorical\n",
    "#Variables\n",
    "#Distinguishing between continuous and categorical variables is \n",
    "#crucial in data analysis because it determines the type of statistical\n",
    "#analysis and modeling that can be performed on the data. Using the wrong\n",
    "#type of analysis for a variable can lead to incorrect conclusions and insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15de3af7-d403-4765-9f19-eb2fea0e9412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6da7ac5-3ba1-4c66-9205-bf7010d3f933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q21. What is feature scaling? How does it help in Machine Learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0c94d62-9117-439a-9d94-1b075598f5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "#Feature scaling, also known as feature normalization or standardization,\n",
    "#is a technique used in machine learning to standardize the range of \n",
    "#independent variables or features of a dataset. It is a crucial step\n",
    "#in data preprocessing that helps to improve the performance and \n",
    "#convergence of machine learning models.\n",
    "\n",
    "\n",
    "#Many machine learning algorithms are sensitive to the scale of the\n",
    "#features in the dataset. When features have different scales,\n",
    "#some algorithms may give more weight to features with larger ranges,\n",
    "#which can lead to biased results. Feature scaling helps to:\n",
    "\n",
    "#1. Reduce the effect of dominant features: Features with large ranges\n",
    "#can dominate the model's predictions, leading to biased results. \n",
    "#Feature scaling ensures that all features are on the same scale, \n",
    "#reducing the effect of dominant features.\n",
    "#2. Improve model convergence: Some algorithms, such as gradient descent,\n",
    "#converge faster when features are scaled.\n",
    "#3. Enhance model interpretability: Feature scaling can make it easier\n",
    "#to compare the coefficients of different features in a model.\n",
    "\n",
    "#Types of Feature Scaling\n",
    "#There are several techniques used for feature scaling, including:\n",
    "\n",
    "#1. Standardization: This technique scales the features to have\n",
    "#a mean of 0 and a standard deviation of 1. It is also known as z-scoring.\n",
    "#2. Normalization: This technique scales the features to a \n",
    "#specific range, usually between 0 and 1. It is also known \n",
    "#as min-max scaling.\n",
    "#3. Log scaling: This technique scales the features using the \n",
    "#logarithmic function. It is useful for features that have a\n",
    "#large range of values.\n",
    "\n",
    "#1. Improves model performance: Feature scaling can improve the accuracy \n",
    "#and robustness of machine learning models.\n",
    "#2. Enhances model interpretability: Feature scaling can make it easier \n",
    "#to understand the relationships between features and the target variable.\n",
    "#3. Reduces the risk of feature dominance: Feature scaling ensures that \n",
    "#all features are treated equally, reducing the risk of feature dominance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1abc0fd8-1267-4996-b377-53159475c64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da37661d-661b-4556-8f81-4f1320cefefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized features:\n",
      "[[-1.22474487 -1.22474487]\n",
      " [ 0.          0.        ]\n",
      " [ 1.22474487  1.22474487]]\n",
      "Normalized fearures:\n",
      "[[0.  0. ]\n",
      " [0.5 0.5]\n",
      " [1.  1. ]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[1,2], [3,4], [5,6]])\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)\n",
    "print(\"Standardized features:\")\n",
    "print(X_std)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_norm = scaler.fit_transform(X)\n",
    "print(\"Normalized fearures:\")\n",
    "print(X_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5a6cba-e000-4257-9e4f-b4cdf468a2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this example, we use the StandardScaler and MinMaxScaler classes\n",
    "#from scikit-learn to standardize and normalize the features of a sample dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce8e225-aeee-4211-a233-a2c52a5e776f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be04cff-cc85-4bbb-8a15-2aeeed695128",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q22. How do we perform scaling in Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c957395f-6dff-4f6f-b9b0-29923261d9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling in Python\n",
    "#Feature scaling is a crucial step in data preprocessing that helps to\n",
    "#standardize the range of independent variables or features of a dataset.\n",
    "#In Python, you can perform scaling using the StandardScaler and MinMaxScaler \n",
    "#classes from the sklearn.preprocessing module.\n",
    "\n",
    "#Standard Scaler\n",
    "#The StandardScaler class scales the features to have a mean of 0 and a\n",
    "#standard deviation of 1. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5be48afe-187b-4ba5-9b7d-65c5f1778f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled features:\n",
      "[[-1.22474487 -1.22474487]\n",
      " [ 0.          0.        ]\n",
      " [ 1.22474487  1.22474487]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([[1,2], [3,4], [5,6]])\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "print(\"Scaled features:\")\n",
    "print(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ddedcd-4b81-42dc-a25f-c067f7171c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2252ef9-15ac-42a2-a88f-1fdd68c67195",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q23. What is sklearn.preprocessing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b600d44c-3dd2-429d-962f-e29e986f3984",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sklearn Preprocessing\n",
    "#sklearn.preprocessing is a module in the scikit-learn library that\n",
    "#provides tools for preprocessing and transforming data. Preprocessing\n",
    "#is an essential step in machine learning pipelines, as it helps to\n",
    "#prepare the data for modeling by transforming and scaling the features.\n",
    "\n",
    "#Key Features of Sklearn Preprocessing\n",
    "#The sklearn.preprocessing module offers a wide range of tools for\n",
    "#preprocessing and transforming data, including:\n",
    "\n",
    "#- Scaling: Scaling techniques, such as StandardScaler and MinMaxScaler,\n",
    "#help to standardize the range of features.\n",
    "#- Normalization: Normalization techniques, such as Normalizer, help to\n",
    "#normalize the data to a specific range or distribution.\n",
    "#- Encoding: Encoding techniques, such as LabelEncoder and OneHotEncoder,\n",
    "#help to convert categorical variables into numerical variables.\n",
    "#- Imputation: Imputation techniques, such as SimpleImputer, help to \n",
    "#handle missing values in the data.\n",
    "\n",
    "#Importance of Sklearn Preprocessing\n",
    "#Preprocessing is crucial in machine learning because it:\n",
    "\n",
    "#- Improves model performance: Preprocessing can improve the accuracy \n",
    "#and robustness of machine learning models.\n",
    "#- Enhances model interpretability: Preprocessing can make it easier \n",
    "#to understand the relationships between features and the target variable.\n",
    "#- Reduces the risk of feature dominance: Preprocessing can ensure that \n",
    "#all features are treated equally, reducing the risk of feature dominance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34e4668a-ef8f-4807-bb29-bb1323ce906a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled features:\n",
      "[[-1.22474487 -1.22474487]\n",
      " [ 0.          0.        ]\n",
      " [ 1.22474487  1.22474487]]\n",
      "Encoded labels:\n",
      "[1 2 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([[1,2], [3,4], [5,6]])\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "y = np.array(['cat', 'dog', 'cat', 'bird'])\n",
    "encoder = LabelEncoder()\n",
    "y_encoded = encoder.fit_transform(y)\n",
    "\n",
    "print(\"Scaled features:\")\n",
    "print(X_scaled)\n",
    "print(\"Encoded labels:\")\n",
    "print(y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6c1d0b-1271-4204-94b3-97b7c65ff5f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc98983a-184d-436a-af56-4d6f657d3dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q24.How do we split data for model fitting (training and testing) in Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4482b7cf-4db2-4af0-9efc-91ebbb7bd235",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting Data for Model Fitting\n",
    "#Splitting data into training and testing sets is a crucial step in \n",
    "#machine learning. In Python, you can use the train_test_split function\n",
    "#from the sklearn.model_selection module to split your data.\n",
    "\n",
    "#Splitting data into training and testing sets is essential because it:\n",
    "\n",
    "#- Prevents overfitting: By evaluating the model on unseen data,\n",
    "#you can prevent overfitting and get a more accurate estimate of the\n",
    "#model's performance.\n",
    "#- Evaluates model performance: The testing set provides an unbiased\n",
    "#evaluation of the model's performance, helping you to tune hyperparameters\n",
    "#and select the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d536fafb-7453-4cdb-8a0e-b07886215e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features:\n",
      "[[ 9 10]\n",
      " [ 5  6]\n",
      " [ 1  2]\n",
      " [ 7  8]]\n",
      "Training labels:\n",
      "[1 1 0 1]\n",
      "Testing features:\n",
      "[[3 4]]\n",
      "Testing labels:\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([[1,2], [3,4], [5,6], [7,8], [9,10]])\n",
    "y = np.array([0,0,1,1,1])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Training features:\")\n",
    "print(X_train)\n",
    "print(\"Training labels:\")\n",
    "print(y_train)\n",
    "print(\"Testing features:\")\n",
    "print(X_test)\n",
    "print(\"Testing labels:\")\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df85f37-8761-4874-b15f-140456266067",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters of Train Test Split\n",
    "#The train_test_split function takes the following parameters:\n",
    "\n",
    "#- X: The feature matrix.\n",
    "#- y: The target variable.\n",
    "#- test_size: The proportion of the data to include in the testing set.\n",
    "#- random_state: The seed used to shuffle the data before splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73441820-b86c-4eb1-9cc1-dc8b7cb50dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q25. Explain data encoding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfafc75-27d5-456b-8ff3-e88e1769ef6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Encoding\n",
    "#Data encoding is a crucial step in data preprocessing that involves \n",
    "#converting categorical or textual data into numerical data that can \n",
    "#be processed by machine learning algorithms. Encoding is necessary \n",
    "#because many machine learning algorithms require numerical input \n",
    "#data to perform calculations and make predictions.\n",
    "\n",
    "#Types of Data Encoding\n",
    "#There are several types of data encoding techniques, including:\n",
    "\n",
    "#- Label Encoding: This technique assigns a unique numerical value\n",
    "#to each category in a categorical variable.\n",
    "#- One-Hot Encoding: This technique creates a new binary feature for \n",
    "#each category in a categorical variable, where a 1 indicates the \n",
    "#presence of the category and a 0 indicates its absence.\n",
    "#- Binary Encoding: This technique converts categorical variables\n",
    "#into binary numbers, which can be more efficient than one-hot encoding \n",
    "#for variables with many categories.\n",
    "#- Ordinal Encoding: This technique assigns numerical values to categories\n",
    "#based on their order or ranking.\n",
    "\n",
    "#Importance of Data Encoding\n",
    "#Data encoding is essential in machine learning because it:\n",
    "\n",
    "#- Enables machine learning algorithms to process categorical data:\n",
    "#Many machine learning algorithms require numerical input data, and\n",
    "#encoding enables these algorithms to process categorical data.\n",
    "#- Improves model performance: Proper encoding can improve the \n",
    "#performance of machine learning models by reducing the impact of\n",
    "#categorical variables on model predictions.\n",
    "#- Enhances data interpretability: Encoding can make it easier to \n",
    "#understand the relationships between categorical variables and the\n",
    "#target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aa891b32-6773-4359-9e58-8330fc77068a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\admin\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.0-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Downloading scikit_learn-1.7.0-cp312-cp312-win_amd64.whl (10.7 MB)\n",
      "   ---------------------------------------- 0.0/10.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.7 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/10.7 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/10.7 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/10.7 MB 1.5 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 1.8/10.7 MB 2.4 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 2.9/10.7 MB 2.9 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 3.9/10.7 MB 3.4 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.2/10.7 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 6.6/10.7 MB 4.1 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 7.9/10.7 MB 4.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 8.9/10.7 MB 4.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.2/10.7 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.7/10.7 MB 4.4 MB/s eta 0:00:00\n",
      "Installing collected packages: scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.5.1\n",
      "    Uninstalling scikit-learn-1.5.1:\n",
      "      Successfully uninstalled scikit-learn-1.5.1\n",
      "Successfully installed scikit-learn-1.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ba02ce3a-74d2-4395-8684-5e48bddf21c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label encoded data:\n",
      "   color    size  color_encoded\n",
      "0    red   small              2\n",
      "1   blue  medium              0\n",
      "2  green   large              1\n",
      "3    red   small              2\n",
      "4   blue  medium              0\n",
      "\n",
      "One-hot encoded data:\n",
      "   size_large  size_medium  size_small\n",
      "0         0.0          0.0         1.0\n",
      "1         0.0          1.0         0.0\n",
      "2         1.0          0.0         0.0\n",
      "3         0.0          0.0         1.0\n",
      "4         0.0          1.0         0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "data = pd.DataFrame({\n",
    "    'color': ['red', 'blue', 'green', 'red', 'blue'],\n",
    "    'size':['small', 'medium', 'large', 'small', 'medium']\n",
    "})\n",
    "le = LabelEncoder()\n",
    "data['color_encoded'] = le.fit_transform(data['color'])\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "encoded_data = ohe.fit_transform(data[['size']])\n",
    "encoded_df = pd.DataFrame(encoded_data, columns=ohe.get_feature_names_out(), index=data.index)\n",
    "print(\"Label encoded data:\")\n",
    "print(data)\n",
    "print(\"\\nOne-hot encoded data:\")\n",
    "print(encoded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c23879f-93c6-420d-b91c-5aaf0881fc4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
