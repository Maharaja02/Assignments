{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c29cd1d0-1635-4664-8128-1aff14e55c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assignment (Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425fc5dd-6f3a-42d7-b8a0-2a12312aac37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b126081e-c41c-493e-b551-dd7f3a31d11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.What is Simple Linear Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30ee4272-658a-4767-a4f7-4cce313c8a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple Linear Regression (SLR) is a fundamental concept in machine learning and statistics. below is the overview:\n",
    "\n",
    "#Definition: Simple Linear Regression is a linear regression model that predicts a continuous output\n",
    "#variable based on a single input feature. It assumes a linear relationship between the input feature\n",
    "#and the output variable.\n",
    "\n",
    "#Mathematical Representation:\n",
    "\n",
    "#y = β0 + β1x + ε\n",
    "\n",
    "#- y: dependent variable (output)\n",
    "#- x: independent variable (input feature)\n",
    "#- β0: intercept or constant term\n",
    "#- β1: slope coefficient\n",
    "#- ε: error term\n",
    "\n",
    "#Key Assumptions:\n",
    "\n",
    "#1. Linearity: The relationship between x and y is linear.\n",
    "#2. Independence: Each observation is independent.\n",
    "#3. Homoscedasticity: Constant variance of residuals.\n",
    "#4. Normality: Residuals are normally distributed.\n",
    "\n",
    "#Use Cases:\n",
    "\n",
    "#1. Predicting continuous outcomes (e.g., stock prices, temperatures)\n",
    "#2. Analyzing relationships between variables (e.g., impact of advertising on sales)\n",
    "\n",
    "#Common Applications:\n",
    "\n",
    "#1. Forecasting\n",
    "#2. Predictive modeling\n",
    "#3. Data analysis and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227e3c7f-417a-4a7f-8875-68e8056639c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c75984e5-7487-4213-bfdd-7731d7dbeb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2. What are the key assumptions of Simple Linear Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de9c3e87-b5c7-4373-a926-2a1801e237d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple Linear Regression Assumptions\n",
    "\n",
    "#Simple Linear Regression (SLR) relies on several key assumptions to ensure the model's validity and accuracy.\n",
    "#These assumptions are crucial for making reliable predictions and inferences.\n",
    "\n",
    "#1. Linearity\n",
    "#The relationship between the independent variable (x) and the dependent variable (y) should be linear. \n",
    "#This means that as x increases or decreases, y changes in a consistent and predictable manner.\n",
    "\n",
    "#2. Independence\n",
    "#Each observation should be independent of the others. This implies that the data points are not paired \n",
    "#or matched, and there is no correlation between the residuals.\n",
    "\n",
    "#3. Homoscedasticity\n",
    "#The variance of the residuals should be constant across all levels of the independent variable. \n",
    "#This means that the spread of the residuals should be consistent throughout the range of x values.\n",
    "\n",
    "#4. Normality\n",
    "#The residuals should be normally distributed. This assumption is crucial for making inferences and \n",
    "#constructing confidence intervals.\n",
    "\n",
    "#5. No Multicollinearity\n",
    "#Although SLR only involves one independent variable, it's essential to note that multicollinearity\n",
    "#is more relevant in multiple linear regression. However, in SLR, we assume that the single independent\n",
    "#variable is not a linear combination of other variables (which is inherently satisfied).\n",
    "\n",
    "#6. No Autocorrelation\n",
    "#The residuals should not be correlated with each other. Autocorrelation can lead to inefficient \n",
    "#estimates and inaccurate predictions.\n",
    "\n",
    "#Importance of Assumptions\n",
    "#These assumptions are vital because they ensure that the model's estimates are reliable, efficient,\n",
    "#and unbiased. Violating these assumptions can lead to:\n",
    "\n",
    "#- Biased or inaccurate predictions\n",
    "#- Incorrect inferences and conclusions\n",
    "#- Poor model performance\n",
    "\n",
    "#Checking Assumptions\n",
    "#To verify these assumptions, we can use various diagnostic tools, such as:\n",
    "\n",
    "#- Scatter plots to check for linearity\n",
    "#- Residual plots to check for homoscedasticity and normality\n",
    "#- Statistical tests (e.g., Shapiro-Wilk test for normality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c19c1da-7b9c-4c23-905f-e90e6567dc4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94d5ca63-1f6d-4f61-be3f-761faa6aca0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3. What does the coefficient m represent in the equation Y=mX+c?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75b5558f-d3eb-46c2-8d99-832fdc86897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coefficient m in the Equation Y = mX + c\n",
    "\n",
    "#In the linear equation Y = mX + c, the coefficient m represents the slope of the line. \n",
    "#It measures the rate of change of the dependent variable Y with respect to the independent \n",
    "#variable X.\n",
    "\n",
    "#Interpretation of m:\n",
    "\n",
    "#- Direction of Relationship: The sign of m indicates the direction of the relationship between\n",
    "#X and Y. A positive value of m indicates a positive relationship (as X increases, Y increases), \n",
    "#while a negative value of m indicates a negative relationship (as X increases, Y decreases).\n",
    "#- Rate of Change: The magnitude of m represents the rate of change of Y with respect to X. \n",
    "#For every one-unit increase in X, Y changes by m units.\n",
    "\n",
    "#Example:\n",
    "\n",
    "#Suppose we have a linear equation Y = 2X + 3, where m = 2. This means that for every one-unit \n",
    "#increase in X, Y increases by 2 units.\n",
    "\n",
    "#Importance of m:\n",
    "\n",
    "#- Understanding Relationships: The slope coefficient m helps us understand the nature and strength\n",
    "#of the relationship between X and Y.\n",
    "#- Predictions: Knowing the value of m enables us to make predictions about Y based on changes in X.\n",
    "\n",
    "#In summary, the coefficient m in the equation Y = mX + c represents the slope of the line, \n",
    "#which is a critical component in understanding the relationship between the variables X and Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757376ac-5764-4c3f-8477-3f92d343c845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1df4a47-1cd3-4d52-9924-89c955221eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4.What does the intercept c represent in the equation Y=mX+c?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "73f59a47-868e-4a19-b76b-c0f8597815c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intercept c in the Equation Y = mX + c\n",
    "\n",
    "#In the linear equation Y = mX + c, the intercept c represents the y-intercept of the line. \n",
    "#It is the value of Y when X is equal to 0.\n",
    "\n",
    "#Interpretation of c:\n",
    "\n",
    "#- Value of Y when X = 0: The intercept c represents the value of the dependent variable Y when the \n",
    "#independent variable X is 0.\n",
    "#- Starting Point: The y-intercept c can be thought of as the starting point of the line on the y-axis.\n",
    "\n",
    "#Example:\n",
    "\n",
    "#Suppose we have a linear equation Y = 2X + 3, where c = 3. This means that when X is 0, Y is equal to 3.\n",
    "\n",
    "#Importance of c:\n",
    "\n",
    "#- Baseline Value: The intercept c provides a baseline value for Y, which can be useful in \n",
    "#understanding the relationship between X and Y.\n",
    "#- Model Interpretation: Knowing the value of c helps in interpreting the results of the model, \n",
    "#especially when X = 0 is a meaningful value in the context of the problem.\n",
    "\n",
    "#Practical Considerations:\n",
    "\n",
    "#- Contextual Relevance: The intercept c may or may not be meaningful depending on the context \n",
    "#of the problem. In some cases, X = 0 may not be a realistic or relevant scenario.\n",
    "#- Model Extrapolation: When using the model for predictions, it's essential to consider whether\n",
    "#the intercept c is reasonable and applicable in the given context.\n",
    "\n",
    "#The intercept c in the equation Y = mX + c represents the y-intercept of the line, providing valuable\n",
    "#information about the relationship between X and Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1c1536-8bd1-459d-8fe9-6082735164e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e251446c-1d52-418f-ae7b-186964b9b6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5. How do we calculate the slope m in Simple Linear Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5daf6adf-0edf-4b50-9202-fdd4c986d50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the Slope (m) in Simple Linear Regression\n",
    "\n",
    "#The slope (m) in Simple Linear Regression (SLR) can be calculated using the following formula:\n",
    "\n",
    "#m = Σ[(xi - x̄)(yi - ȳ)] / Σ(xi - x̄)²\n",
    "\n",
    "#where:\n",
    "\n",
    "#- xi: individual data points of the independent variable X\n",
    "#- x̄: mean of the independent variable X\n",
    "#- yi: individual data points of the dependent variable Y\n",
    "#- ȳ: mean of the dependent variable Y\n",
    "\n",
    "#Step-by-Step Calculation:\n",
    "\n",
    "#1. Calculate the mean of X (x̄) and Y (ȳ)\n",
    "#2. Calculate the deviations from the mean for each data point (xi - x̄) and (yi - ȳ)\n",
    "#3. Calculate the product of the deviations for each data point (xi - x̄)(yi - ȳ)\n",
    "#4. Calculate the sum of the products of the deviations Σ[(xi - x̄)(yi - ȳ)]\n",
    "#5. Calculate the sum of the squared deviations of X Σ(xi - x̄)²\n",
    "#6. Divide the sum of the products of the deviations by the sum of the squared deviations of X to \n",
    "#get the slope (m)\n",
    "\n",
    "#Alternative Formula:\n",
    "\n",
    "#m = r * (σy / σx)\n",
    "\n",
    "#- r: correlation coefficient between X and Y\n",
    "#- σy: standard deviation of Y\n",
    "#- σx: standard deviation of X\n",
    "\n",
    "#Importance of Slope Calculation:\n",
    "\n",
    "#- Understanding Relationships: The slope (m) helps us understand the direction and strength of \n",
    "#the relationship between X and Y.\n",
    "#- Predictions: Knowing the slope enables us to make predictions about Y based on changes in X.\n",
    "\n",
    "#Calculating the slope (m) in Simple Linear Regression involves using the formula that takes into\n",
    "#account the deviations from the mean of both X and Y. This calculation is crucial for understanding\n",
    "#the relationship between the variables and making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421207ad-6c43-4ea6-b2df-7f8ec970e0bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "874038e6-ca61-494c-a67e-2ccb6c7a4a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6.What is the purpose of the least squares method in Simple Linear Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bcb7b7b3-16d2-4ab6-a918-5893f39c4543",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Purpose of the Least Squares Method in Simple Linear Regression\n",
    "\n",
    "#The Least Squares Method is a widely used statistical technique in Simple Linear Regression (SLR)\n",
    "#that serves a crucial purpose in estimating the parameters of a linear regression model. The primary \n",
    "#objective of the Least Squares Method is to determine the best-fitting line that minimizes the sum of\n",
    "#the squared residuals between the observed data points and the predicted values.\n",
    "\n",
    "#Key Purpose:\n",
    "\n",
    "#1. Minimizing Residuals: The Least Squares Method aims to minimize the sum of the squared residuals,\n",
    "#which represents the difference between the observed and predicted values. By minimizing these residuals,\n",
    "#the method ensures that the estimated regression line is as close as possible to the actual data points.\n",
    "#2. Estimating Parameters: The method provides estimates of the slope (m) and intercept (c) of the \n",
    "#linear regression line. These estimates are obtained by finding the values of m and c that result in the\n",
    "#smallest possible sum of squared residuals.\n",
    "\n",
    "#Importance in Machine Learning and Statistics:\n",
    "\n",
    "#1. Model Fitting: The Least Squares Method is essential for fitting a linear regression model\n",
    "#to a dataset. By minimizing the sum of squared residuals, the method ensures that the model provides \n",
    "#the best possible fit to the data.\n",
    "#2. Prediction Accuracy: By estimating the parameters of the linear regression model, the Least Squares \n",
    "#Method enables accurate predictions of the dependent variable based on the independent variable.\n",
    "#3. Model Evaluation: The method facilitates model evaluation through metrics like R-squared, which\n",
    "#measures the proportion of variance in the dependent variable explained by the independent variable.\n",
    "\n",
    "#Benefits:\n",
    "\n",
    "#1. Optimal Estimates: Under certain assumptions (e.g., linearity, homoscedasticity, normality), \n",
    "#the Least Squares Method provides optimal estimates of the regression coefficients.\n",
    "#2. Goodness of Fit: The method allows for the evaluation of the model's goodness of fit, enabling\n",
    "#researchers to assess the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aec4f09-f52f-4611-902d-4cfdaca9dc03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c9e5309b-8b36-4b0c-975b-8ac2ee676176",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7.How is the coefficient of determination (R²) interpreted in Simple Linear Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ace0c353-7822-40b4-afa1-01a9d9310104",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interpretation of Coefficient of Determination (R²) in Simple Linear Regression\n",
    "\n",
    "#The Coefficient of Determination, commonly denoted as R², is a statistical measure used \n",
    "#in Simple Linear Regression (SLR) to evaluate the goodness of fit of a regression model. \n",
    "#It quantifies the proportion of variance in the dependent variable (Y) that is explained \n",
    "#by the independent variable (X).\n",
    "\n",
    "#Interpretation of R²:\n",
    "\n",
    "#1. Proportion of Variance Explained: R² represents the proportion of total variance in Y that is\n",
    "#accounted for by the regression model. It ranges from 0 to 1, where:\n",
    "#- R² = 0 indicates that the model does not explain any of the variance in Y.\n",
    "#- R² = 1 indicates that the model explains all of the variance in Y.\n",
    "#2. Goodness of Fit: A higher R² value indicates a better fit of the model to the data. It suggests\n",
    "#that more of the variance in Y is explained by the model, making it a more reliable predictor.\n",
    "\n",
    "#Example:\n",
    "\n",
    "#Suppose we have a Simple Linear Regression model with an R² value of 0.85. This means that 85% \n",
    "#of the variance in the dependent variable (Y) is explained by the independent variable (X). \n",
    "#The remaining 15% of the variance is attributed to other factors not included in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2f259c45-c0a1-43c5-b067-9b28817aaf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8.What is Multiple Linear Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "18ddee87-6b6c-4845-a72b-e3b65218dbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiple Linear Regression (MLR)\n",
    "\n",
    "#Multiple Linear Regression is a statistical technique used in machine learning and data analysis\n",
    "#to model the relationship between a dependent variable (Y) and multiple independent variables (X1, X2, ..., Xn).\n",
    "#It extends the concept of Simple Linear Regression by incorporating multiple predictors to explain the variability \n",
    "#in the response variable.\n",
    "\n",
    "#Mathematical Representation:\n",
    "\n",
    "#Y = β0 + β1X1 + β2X2 + … + βnXn + ε\n",
    "\n",
    "#- Y: dependent variable\n",
    "#- X1, X2, …, Xn: independent variables\n",
    "#- β0: intercept or constant term\n",
    "#- β1, β2, …, βn: coefficients of the independent variables\n",
    "#- ε: error term\n",
    "\n",
    "#Key Features:\n",
    "\n",
    "#1. Multiple Predictors: MLR allows for the inclusion of multiple independent variables, enabling \n",
    "#the model to capture complex relationships and interactions between variables.\n",
    "#2. Coefficient Estimation: The model estimates coefficients (β) for each independent variable, \n",
    "#indicating the change in Y for a one-unit change in the corresponding X, while holding other variables \n",
    "#constant.\n",
    "#3. Assumptions: MLR assumes linearity, independence, homoscedasticity, normality, and no multicollinearity\n",
    "#between the independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e8bbf9-7f37-4ea4-b64f-1ba50c9fd50a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2fc69839-d7f8-492c-80f2-a26dead14ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q9. What is the main difference between Simple and Multiple Linear Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2465b202-cc00-4ef9-8331-ecab522c3a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Difference between Simple and Multiple Linear Regression\n",
    "\n",
    "#The primary distinction between Simple Linear Regression (SLR) and Multiple Linear Regression (MLR)\n",
    "#lies in the number of independent variables used in the model to predict the dependent variable.\n",
    "\n",
    "#Simple Linear Regression (SLR):\n",
    "\n",
    "#- Single Predictor: SLR involves only one independent variable (X) to predict the dependent variable (Y).\n",
    "#- Model Form: The relationship is modeled as Y = β0 + β1X + ε, where β0 is the intercept, β1 is the slope \n",
    "#coefficient, and ε is the error term.\n",
    "\n",
    "#Multiple Linear Regression (MLR):\n",
    "\n",
    "#- Multiple Predictors: MLR involves two or more independent variables (X1, X2, ..., Xn) to predict \n",
    "#the dependent variable (Y).\n",
    "#- Model Form: The relationship is modeled as Y = β0 + β1X1 + β2X2 + … + βnXn + ε, where β0 is the \n",
    "#intercept, β1, β2, ..., βn are the coefficients for each independent variable, and ε is the error term.\n",
    "\n",
    "#Key Differences:\n",
    "\n",
    "#1. Number of Predictors: The most obvious difference is the number of independent variables included \n",
    "#in the model. SLR has one predictor, while MLR has multiple predictors.\n",
    "#2. Model Complexity: MLR models are more complex because they account for the effects of multiple variables\n",
    "#simultaneously, allowing for a more nuanced understanding of the relationships between variables.\n",
    "#3. Interpretation of Coefficients: In SLR, the coefficient represents the change in Y for a one-unit \n",
    "#change in X. In MLR, each coefficient represents the change in Y for a one-unit change in the corresponding X,\n",
    "#while holding all other X variables constant.\n",
    "\n",
    "#Implications:\n",
    "\n",
    "#- Predictive Power: MLR typically offers greater predictive power than SLR because it can account for\n",
    "#the effects of multiple variables.\n",
    "#- Model Assumptions: Both SLR and MLR require similar assumptions (linearity, independence, homoscedasticity,\n",
    "#normality of residuals), but MLR also requires careful consideration of multicollinearity between predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ac3eac-5d23-4128-a8f8-b51a64adbc58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1370b73c-f136-48d3-9c63-94fdd3d69c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q10.What are the key assumptions of Multiple Linear Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d14c03ad-a9f2-46f5-9ae5-85c4991587a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Key Assumptions of Multiple Linear Regression\n",
    "\n",
    "#Multiple Linear Regression (MLR) relies on several key assumptions to ensure the validity and accuracy \n",
    "#of the model's estimates and predictions. These assumptions are critical for making reliable inferences \n",
    "#and interpretations.\n",
    "\n",
    "#1. Linearity\n",
    "#The relationship between each independent variable and the dependent variable should be linear. \n",
    "#This means that as each independent variable changes, the dependent variable changes in a consistent\n",
    "#and predictable manner.\n",
    "\n",
    "#2. Independence\n",
    "#The observations should be independent of each other. This implies that the data points are not paired or\n",
    "#matched, and there is no correlation between the residuals.\n",
    "\n",
    "#3. Homoscedasticity\n",
    "#The variance of the residuals should be constant across all levels of the independent variables. \n",
    "#This means that the spread of the residuals should be consistent throughout the range of predicted values.\n",
    "\n",
    "#4. Normality\n",
    "#The residuals should be normally distributed. This assumption is crucial for making inferences and \n",
    "#constructing confidence intervals.\n",
    "\n",
    "#5. No Multicollinearity\n",
    "#The independent variables should not be highly correlated with each other. Multicollinearity can lead \n",
    "#to unstable estimates of the regression coefficients and make it difficult to interpret the results.\n",
    "\n",
    "#6. No Autocorrelation\n",
    "#The residuals should not be correlated with each other. Autocorrelation can lead to inefficient estimates \n",
    "#and inaccurate predictions.\n",
    "\n",
    "#Importance of Assumptions\n",
    "#These assumptions are vital because they ensure that the model's estimates are reliable, efficient, \n",
    "#and unbiased. Violating these assumptions can lead to:\n",
    "\n",
    "#- Biased or inaccurate predictions\n",
    "#- Incorrect inferences and conclusions\n",
    "#- Poor model performance\n",
    "\n",
    "#Checking Assumptions\n",
    "#To verify these assumptions, we can use various diagnostic tools, such as:\n",
    "\n",
    "# Scatter plots to check for linearity\n",
    "#- Residual plots to check for homoscedasticity and normality\n",
    "#- Variance Inflation Factor (VIF) to check for multicollinearity\n",
    "#- Durbin-Watson test to check for autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fabf8c-a495-4ae6-ad41-c6fe1feaa034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b8805358-b266-4d5b-8286-b93a46a3a22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q11. What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ecb697b1-d399-4f0b-80a5-e744998b8813",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heteroscedasticity in Multiple Linear Regression\n",
    "\n",
    "#Heteroscedasticity refers to the condition in which the variance of the residuals is not constant \n",
    "#across all levels of the independent variables in a regression model. In other words, the spread of \n",
    "#the residuals changes as the values of the independent variables change.\n",
    "\n",
    "#Causes of Heteroscedasticity:\n",
    "\n",
    "#1. Non-constant variance: The variance of the residuals may increase or decrease as the values of\n",
    "#the independent variables change.\n",
    "#2. Outliers: Presence of outliers in the data can lead to heteroscedasticity.\n",
    "#3. Non-linear relationships: Non-linear relationships between the independent variables and the \n",
    "#dependent variable can also lead to heteroscedasticity.\n",
    "\n",
    "#Effects of Heteroscedasticity on Multiple Linear Regression:\n",
    "\n",
    "#1. Inefficient estimates: Heteroscedasticity can lead to inefficient estimates of the regression\n",
    "#coefficients, which can result in incorrect conclusions.\n",
    "#2. Biased standard errors: Heteroscedasticity can also lead to biased standard errors, which can \n",
    "#affect the accuracy of hypothesis tests and confidence intervals.\n",
    "#3. Poor predictions: Heteroscedasticity can result in poor predictions, especially for observations\n",
    "#with high or low values of the independent variables.\n",
    "\n",
    "#Consequences:\n",
    "\n",
    "#1. Incorrect inferences: Heteroscedasticity can lead to incorrect inferences about the relationships\n",
    "#between the variables.\n",
    "#2. Overestimation or underestimation: Heteroscedasticity can result in overestimation or underestimation\n",
    "#of the effects of the independent variables on the dependent variable.\n",
    "\n",
    "#Detection and Remedies:\n",
    "\n",
    "#1. Residual plots: Visual inspection of residual plots can help detect heteroscedasticity.\n",
    "#2. Breusch-Pagan test: The Breusch-Pagan test is a statistical test that can be used to detect \n",
    "#heteroscedasticity.\n",
    "#3. Transformation: Transforming the dependent variable or independent variables can help \n",
    "#stabilize the variance and reduce heteroscedasticity.\n",
    "#4. Weighted least squares: Using weighted least squares regression can also help address heteroscedasticity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f887f245-9936-4493-a10d-6e39726c1700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a96c3140-16d1-413f-8c4c-8fb64f5141b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q12.How can you improve a Multiple Linear Regression model with high multicollinearity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "acd85599-1126-4c26-a226-04ab008a9909",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Improving a Multiple Linear Regression Model with High Multicollinearity\n",
    "\n",
    "#High multicollinearity in a Multiple Linear Regression (MLR) model can lead to unstable \n",
    "#estimates of the regression coefficients, inflated variance, and incorrect inferences. \n",
    "#To improve a model with high multicollinearity, consider the following strategies:\n",
    "\n",
    "#1. Detect Multicollinearity\n",
    "#Before taking any corrective action, it's essential to detect multicollinearity using metrics such as:\n",
    "#- Variance Inflation Factor (VIF): A VIF value greater than 5 or 10 indicates high multicollinearity.\n",
    "#- Tolerance: A tolerance value less than 0.1 or 0.2 indicates high multicollinearity.\n",
    "#- Correlation Matrix: Examine the correlation matrix to identify highly correlated independent variables.\n",
    "\n",
    "#2. Remove Highly Correlated Predictors\n",
    "#One way to address multicollinearity is to remove one or more of the highly correlated predictors \n",
    "#from the model. This can be done based on:\n",
    "#- Domain knowledge: Remove variables that are less relevant or redundant based on domain expertise.\n",
    "#- Statistical criteria: Remove variables with high VIF values or low tolerance values.\n",
    "\n",
    "#3. Combine Correlated Predictors\n",
    "#If multiple predictors are highly correlated and measure similar constructs, consider\n",
    "#combining them into a single predictor through:\n",
    "#- Dimensionality reduction techniques: Use techniques like Principal Component Analysis (PCA) \n",
    "#or Factor Analysis to reduce the number of predictors.\n",
    "#- Creating composite scores: Create a composite score by averaging or summing the highly \n",
    "#correlated predictors.\n",
    "\n",
    "#4. Regularization Techniques\n",
    "#Regularization techniques can help mitigate multicollinearity by adding a penalty term to the\n",
    "#loss function:\n",
    "#- Ridge Regression: Adds a penalty term proportional to the square of the magnitude of the coefficients.\n",
    "#- Lasso Regression: Adds a penalty term proportional to the absolute value of the coefficients, \n",
    "#which can set some coefficients to zero.\n",
    "\n",
    "#5. Collect More Data\n",
    "#If possible, collect more data to reduce multicollinearity. Additional data can help to:\n",
    "#- Stabilize estimates: More data can stabilize the estimates of the regression coefficients and \n",
    "#reduce the impact of multicollinearity.\n",
    "#- Identify relationships: With more data, you may be able to identify relationships between variables\n",
    "#that were not apparent with a smaller dataset.\n",
    "\n",
    "#6. Use Partial Least Squares Regression (PLS)\n",
    "#PLS regression is a technique that combines features of PCA and MLR. It can handle high \n",
    "#multicollinearity by:\n",
    "#- Creating latent variables: PLS creates latent variables that capture the variance in both the \n",
    "#predictors and the response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8810d1ed-e6c2-4482-a950-de6ae5662cfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1f828b0b-0b84-43d9-8b97-1d54db415209",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q13. What are some common techniques for transforming categorical variables for use in regression models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "697c5274-4d1c-4cf0-9f81-fb1f8d995514",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming Categorical Variables for Regression Models\n",
    "\n",
    "#Categorical variables are variables that take on discrete values or categories. To use these variables \n",
    "#in regression models, they need to be transformed into numerical variables. Here are some common techniques:\n",
    "\n",
    "#1. One-Hot Encoding (OHE)\n",
    "#One-hot encoding is a technique where each category is represented as a binary vector. For a categorical\n",
    "#variable with k categories, k-1 binary variables are created.\n",
    "\n",
    "#- Example: For a variable \"Color\" with categories \"Red\", \"Blue\", and \"Green\", OHE would create two binary \n",
    "#variables: \"Is_Blue\" and \"Is_Green\".\n",
    "\n",
    "#2. Label Encoding\n",
    "#Label encoding assigns a numerical value to each category. This technique is suitable for ordinal \n",
    "#categorical variables.\n",
    "\n",
    "#- Example: For a variable \"Size\" with categories \"Small\", \"Medium\", and \"Large\", label encoding would \n",
    "#assign values 1, 2, and 3, respectively.\n",
    "\n",
    "#3. Binary Encoding\n",
    "#Binary encoding is similar to one-hot encoding but uses binary digits to represent each category.\n",
    "\n",
    "#- Example: For a variable \"Color\" with categories \"Red\", \"Blue\", and \"Green\", binary encoding would \n",
    "#represent \"Red\" as 00, \"Blue\" as 01, and \"Green\" as 10.\n",
    "\n",
    "#4. Dummy Coding\n",
    "#Dummy coding is similar to one-hot encoding but uses k-1 binary variables to represent k categories.\n",
    "#One category is chosen as the reference category.\n",
    "\n",
    "#- Example: For a variable \"Color\" with categories \"Red\", \"Blue\", and \"Green\", dummy coding would \n",
    "#create two binary variables: \"Is_Blue\" and \"Is_Green\", with \"Red\" as the reference category.\n",
    "\n",
    "#5. Effect Coding\n",
    "#Effect coding is similar to dummy coding but uses a different coding scheme. It compares the mean \n",
    "#of each category to the grand mean.\n",
    "\n",
    "#Choosing the Right Technique\n",
    "#The choice of technique depends on the type of categorical variable and the specific requirements of\n",
    "#the model. Consider the following factors:\n",
    "\n",
    "#- Ordinal vs. Nominal: For ordinal variables, label encoding or effect coding may be suitable. For nominal\n",
    "#variables, one-hot encoding or dummy coding may be more appropriate.\n",
    "#- Number of categories: For variables with many categories, binary encoding or hashing may be more efficient.\n",
    "#- Model requirements: Some models, such as decision trees, can handle categorical variables directly. \n",
    "#Others, such as linear regression, require numerical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4972a0-2a7c-4426-bcb4-5e155f052468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "44e6f982-e6ee-4fe5-9260-18a7755854bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q14. What is the role of interaction terms in Multiple Linear Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7432fa7e-ac55-4f00-aca7-7910bce36471",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Role of Interaction Terms in Multiple Linear Regression\n",
    "\n",
    "#Interaction terms in Multiple Linear Regression (MLR) are used to capture the interaction effects \n",
    "#between two or more independent variables on the dependent variable. These terms allow the effect \n",
    "#of one independent variable on the dependent variable to depend on the level of another independent\n",
    "#variable.\n",
    "\n",
    "#1. Capturing Non-Additive Effects: Interaction terms help to capture non-additive effects between \n",
    "#independent variables, which can lead to a better understanding of the relationships between variables.\n",
    "#2. Improving Model Fit: Including interaction terms can improve the fit of the model by accounting \n",
    "#for the interactions between variables, leading to more accurate predictions.\n",
    "#3. Revealing Hidden Relationships: Interaction terms can reveal hidden relationships between \n",
    "#variables that may not be apparent when only considering main effects.\n",
    "\n",
    "#1. Creating Interaction Variables: Create new variables that represent the product of two or more\n",
    "#independent variables.\n",
    "#2. Adding Interaction Terms to the Model: Include the interaction variables in the MLR model,\n",
    "#along with the main effects.\n",
    "\n",
    "#Interpretation of Interaction Terms:\n",
    "\n",
    "#1. Coefficient Interpretation: The coefficient of an interaction term represents the change in the\n",
    "#effect of one independent variable on the dependent variable for a one-unit change in another independent\n",
    "#variable.\n",
    "#2. Visualizing Interactions: Visualizing the interaction effects can help to understand the nature of the\n",
    "#relationships between variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277b50ea-e630-4cf8-9669-12c4ae252505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2636459-6ebd-4878-849e-42611b64d2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q15. How can the interpretation of intercept differ between Simple and Multiple Linear Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8ec353e-6d56-441f-8f1a-9cabf3be3c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interpretation of Intercept in Simple and Multiple Linear Regression\n",
    "\n",
    "#The intercept in linear regression represents the expected value of the dependent variable when\n",
    "#all independent variables are set to zero. However, the interpretation of the intercept can differ\n",
    "#between Simple Linear Regression (SLR) and Multiple Linear Regression (MLR).\n",
    "\n",
    "#Simple Linear Regression (SLR)\n",
    "#In SLR, the intercept represents the expected value of the dependent variable when the single\n",
    "#independent variable is set to zero. This interpretation is often meaningful, especially when the \n",
    "#independent variable is a continuous variable that can take on values close to zero.\n",
    "\n",
    "#- Example: Suppose we have a model that predicts house prices based on the number of bedrooms.\n",
    "#The intercept would represent the expected price of a house with zero bedrooms, which may not be\n",
    "#meaningful in this context.\n",
    "\n",
    "#Multiple Linear Regression (MLR)\n",
    "#In MLR, the intercept represents the expected value of the dependent variable when all independent\n",
    "#variables are set to zero. However, this interpretation can be more complex and less meaningful, \n",
    "#especially when there are multiple independent variables that cannot simultaneously be zero.\n",
    "\n",
    "#- Example: Suppose we have a model that predicts house prices based on the number of bedrooms and\n",
    "#the size of the house. The intercept would represent the expected price of a house with zero bedrooms\n",
    "#and zero size, which is likely not meaningful in this context.\n",
    "\n",
    "#Key Differences\n",
    "#1. Contextual Meaningfulness: In SLR, the intercept often has a clear and meaningful interpretation.\n",
    "#In MLR, the intercept may not be as meaningful, especially when the independent variables cannot \n",
    "#simultaneously be zero.\n",
    "#2. Interpretation Depends on Variables: The interpretation of the intercept depends on the specific\n",
    "#variables included in the model. In MLR, the intercept is influenced by the scales and units of all\n",
    "#independent variables.\n",
    "#3. Model Assumptions: The interpretation of the intercept assumes that the model is correctly \n",
    "#specified and that the relationships between variables are accurately represented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6191ccfb-c12c-4afc-933a-5f4e41cafc7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05b480a4-d3f1-4fc8-b205-09fc74942045",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q16.What is the significance of the slope in regression analysis, and how does it affect predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0374230c-7e99-4aa0-a681-b7a0a8e0c56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Significance of Slope in Regression Analysis\n",
    "\n",
    "#The slope in regression analysis represents the change in the dependent variable for a one-unit \n",
    "#change in the independent variable, while holding all other variables constant. The slope is a \n",
    "#crucial component of regression models, and its significance can be understood in several ways:\n",
    "\n",
    "#Interpretation of Slope\n",
    "#1. Direction of Relationship: The sign of the slope indicates the direction of the relationship \n",
    "#between the independent variable and the dependent variable. A positive slope indicates a positive\n",
    "#relationship, while a negative slope indicates a negative relationship.\n",
    "#2. Magnitude of Change: The magnitude of the slope represents the amount of change in the dependent\n",
    "#variable for a one-unit change in the independent variable. A larger slope indicates a greater change\n",
    "#in the dependent variable.\n",
    "#3. Predictive Power: The slope is used to make predictions about the dependent variable based on the\n",
    "#value of the independent variable. A significant slope indicates that the independent variable is a \n",
    "#strong predictor of the dependent variable.\n",
    "\n",
    "#Effect on Predictions\n",
    "#1. Accuracy of Predictions: The slope plays a critical role in determining the accuracy of predictions.\n",
    "#A well-estimated slope ensures that predictions are reliable and accurate.\n",
    "#2. Sensitivity to Changes: The slope determines the sensitivity of the predictions to changes in the \n",
    "#independent variable. A large slope indicates that small changes in the independent variable can result\n",
    "#in large changes in the predicted value of the dependent variable.\n",
    "#3. Model Interpretation: The slope is essential for interpreting the results of the regression model.\n",
    "#It helps to understand the relationships between variables and identify the most important predictors.\n",
    "\n",
    "#Significance Testing\n",
    "#1. Hypothesis Testing: The significance of the slope can be tested using hypothesis testing. \n",
    "#A significant slope indicates that the relationship between the independent variable and the \n",
    "#dependent variable is statistically significant.\n",
    "#2. p-value: The p-value associated with the slope indicates the probability of observing the estimated \n",
    "#slope by chance. A low p-value (typically < 0.05) indicates that the slope is statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3993ad-10dc-4502-a3b7-7e868e3f2eb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9ef34bc-7d37-4b95-b3ed-93cd354eb25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q17. How does the intercept in a regression model provide context for the relationship between variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75836d62-7b0a-4844-a06d-53741e4b76f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intercept in Regression Models: Providing Context for Relationships\n",
    "\n",
    "#The intercept in a regression model represents the expected value of the dependent variable when \n",
    "#all independent variables are set to zero. While the intercept may seem like a simple constant, \n",
    "#it provides valuable context for understanding the relationships between variables in the model.\n",
    "\n",
    "#Baseline Value\n",
    "#1. Reference Point: The intercept serves as a reference point or baseline value for the dependent \n",
    "#variable. It provides a starting point for understanding the relationships between variables.\n",
    "#2. Contextualizing Relationships: By knowing the intercept, you can better understand the direction \n",
    "#and magnitude of the relationships between variables. For example, a positive slope may indicate \n",
    "#a positive relationship, but the intercept helps to contextualize this relationship.\n",
    "\n",
    "#Interpretation of Intercept\n",
    "#1. Meaningful Zero Point: When the independent variables have a meaningful zero point (e.g., age, income),\n",
    "#the intercept represents the expected value of the dependent variable for an individual with a value of zero\n",
    "#for all independent variables.\n",
    "#2. Adjusting for Other Variables: In multiple regression, the intercept adjusts for the effects of other\n",
    "#variables in the model. It represents the expected value of the dependent variable when all independent\n",
    "#variables are set to zero, while controlling for the effects of other variables.\n",
    "\n",
    "#Impact on Predictions\n",
    "#1. Shifting Predictions: The intercept shifts the predictions up or down, depending on its value. A large\n",
    "#intercept can result in higher predicted values, while a small intercept can result in lower predicted values.\n",
    "#2. Model Calibration: The intercept helps to calibrate the model to the specific problem or population being\n",
    "#studied. By accurately estimating the intercept, you can ensure that the model is well-calibrated and provides\n",
    "#reliable predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb6a386-853f-4009-9787-ad2b6e9ef829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aeae2b9e-e25b-4ec6-9668-89a76663b957",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q18. What are the limitations of using R² as a sole measure of model performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27c251cd-b1af-4faa-9e39-e6616f60156d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limitations of R² as a Sole Measure of Model Performance\n",
    "#R², also known as the coefficient of determination, measures the proportion of variance in the\n",
    "#dependent variable explained by the independent variables in a regression model. While R² provides\n",
    "#valuable insights into model fit, relying solely on it can be misleading due to several limitations:\n",
    "\n",
    "#1. Sensitivity to Model Complexity\n",
    "#R² increases with the addition of more predictors, regardless of their significance. This can \n",
    "#lead to overfitting, where the model fits the noise in the training data rather than the underlying\n",
    "#signal.\n",
    "\n",
    "#2. Overemphasis on Explained Variability\n",
    "#R² focuses exclusively on the proportion of variability explained, ignoring other crucial aspects\n",
    "#of model performance, such as predictive accuracy on unseen data.\n",
    "\n",
    "#3. Inapplicability to Non-Linear or Heteroscedastic Models\n",
    "#R² may not accurately depict model fit in situations with non-linear relationships or uneven error variances.\n",
    "\n",
    "#4. Misinterpretation of Model Quality\n",
    "#A high R² doesn't necessarily imply a good model. It only indicates a strong association, not \n",
    "#causation. Models with low R² values might still be useful for prediction or explanation, especially\n",
    "#in fields with high variability.\n",
    "\n",
    "#5. Ignoring Residual Analysis\n",
    "#Neglecting residual analysis can lead to overlooking critical issues, such as:\n",
    "#- Heteroscedasticity: Non-constant variance across levels of independent variables.\n",
    "#- Non-Linearity: Systematic patterns indicating model mis-specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95be94b9-7257-4d9e-90b3-c4ccc0fd026e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc6a4000-ecac-4ec6-9427-78ce51a258e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q19.How would you interpret a large standard error for a regression coefficient?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f635723-bd0c-44e2-846c-7d614c4e1b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interpreting a Large Standard Error for a Regression Coefficient\n",
    "#A large standard error for a regression coefficient indicates uncertainty in the estimate of the\n",
    "#coefficient. Here's how to interpret it:\n",
    "\n",
    "#Implications of a Large Standard Error\n",
    "#1. Uncertainty in Estimates: A large standard error suggests that the estimate of the regression \n",
    "#coefficient is imprecise. This uncertainty can lead to difficulties in interpreting the relationship\n",
    "#between the independent variable and the dependent variable.\n",
    "#2. Wide Confidence Intervals: A large standard error results in wide confidence intervals for the\n",
    "#regression coefficient. This means that the true value of the coefficient could lie within a broad range,\n",
    "#making it challenging to pinpoint the exact relationship.\n",
    "#3. Low Precision: A large standard error indicates low precision in the estimate of the regression coefficient.\n",
    "#This can be due to various factors, such as a small sample size, high variability in the data, or multicollinearity\n",
    "#between independent variables.\n",
    "\n",
    "#Possible Causes of a Large Standard Error\n",
    "#1. Small Sample Size: A small sample size can lead to imprecise estimates of regression coefficients,\n",
    "#resulting in large standard errors.\n",
    "#2. High Variability in the Data: High variability in the dependent variable or independent variables can\n",
    "#increase the standard error of the regression coefficient.\n",
    "#3. Multicollinearity: Multicollinearity between independent variables can inflate the standard error of \n",
    "#the regression coefficients, making it challenging to interpret the relationships.\n",
    "\n",
    "#Consequences for Model Interpretation and Prediction\n",
    "#1. Reduced Confidence in Predictions: A large standard error for a regression coefficient can reduce\n",
    "#confidence in the predictions made by the model. This is because the uncertainty in the coefficient \n",
    "#estimate can propagate to the predictions.\n",
    "#2. Difficulty in Identifying Significant Relationships: A large standard error can make it challenging \n",
    "#to identify significant relationships between variables. This is because the uncertainty in the coefficient\n",
    "#estimate can lead to non-significant p-values.\n",
    "\n",
    "#Addressing Large Standard Errors\n",
    "#1. Collect More Data: Increasing the sample size can help reduce the standard error and improve the\n",
    "#precision of the estimates.\n",
    "#2. Data Transformation: Transforming the data, such as scaling or normalizing, can help reduce the \n",
    "#variability and improve the precision of the estimates.\n",
    "#3. Regularization Techniques: Regularization techniques, such as Ridge or Lasso regression, can help \n",
    "#reduce the impact of multicollinearity and improve the precision of the estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fe89cf-d3b2-44cd-be45-9ddb7f550015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "122b4edc-e5b2-424f-82ac-07dd850efcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q20.How can heteroscedasticity be identified in residual plots, and why is it important to address it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "759aba92-2996-4b0a-b82a-db03f36b97b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identifying and Addressing Heteroscedasticity in Residual Plots\n",
    "#Heteroscedasticity refers to the condition where the variance of the residuals is not constant\n",
    "#across different levels of the independent variable(s). Identifying and addressing heteroscedasticity \n",
    "#is crucial for ensuring the reliability and accuracy of regression models.\n",
    "\n",
    "#Identifying Heteroscedasticity in Residual Plots\n",
    "#1. Residuals vs. Fitted Plot: A plot of residuals against fitted values can help identify heteroscedasticity.\n",
    "#If the residuals exhibit a pattern, such as a funnel shape or a curve, it may indicate heteroscedasticity.\n",
    "#2. Residuals vs. Independent Variable Plot: Plotting residuals against each independent variable can also \n",
    "#help identify heteroscedasticity. If the residuals exhibit a pattern or varying spread across different\n",
    "#levels of the independent variable, it may indicate heteroscedasticity.\n",
    "\n",
    "#Characteristics of Heteroscedastic Residuals\n",
    "#1. Non-Constant Variance: Heteroscedastic residuals exhibit non-constant variance across different levels \n",
    "#of the independent variable(s).\n",
    "#2. Patterns or Trends: Heteroscedastic residuals may exhibit patterns or trends, such as increasing or decreasing \n",
    "#variance, across different levels of the independent variable(s).\n",
    "\n",
    "#1. Biased Standard Errors: Heteroscedasticity can lead to biased standard errors, which can result\n",
    "#in incorrect inferences about the relationships between variables.\n",
    "#2. Inefficient Estimates: Heteroscedasticity can lead to inefficient estimates of regression coefficients,\n",
    "#which can result in reduced precision and accuracy.\n",
    "#3. Model Misspecification: Heteroscedasticity can indicate model misspecification, such as omitted variables\n",
    "#or incorrect functional form.\n",
    "\n",
    "#Consequences of Ignoring Heteroscedasticity\n",
    "#1. Incorrect Inferences: Ignoring heteroscedasticity can lead to incorrect inferences about the \n",
    "#relationships between variables.\n",
    "#2. Poor Predictive Performance: Ignoring heteroscedasticity can result in poor predictive performance,\n",
    "#as the model may not accurately capture the relationships between variables.\n",
    "\n",
    "#Addressing Heteroscedasticity\n",
    "#1. Data Transformation: Transforming the data, such as logarithmic or square root transformation, \n",
    "#can help stabilize the variance and reduce heteroscedasticity.\n",
    "#2. Weighted Least Squares (WLS): WLS regression can be used to account for heteroscedasticity by assigning\n",
    "#different weights to observations based on their variance.\n",
    "#3. Robust Standard Errors: Robust standard errors, such as Huber-White standard errors, can be used to account\n",
    "#for heteroscedasticity and provide more accurate inferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706c55ca-0f65-4ccc-ac02-649aa17fda2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1bf8f3a7-c30d-4572-b907-cf9356862c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q21. What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R²?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8931e7e2-0006-4769-9a8d-6e5c1e4cc359",
   "metadata": {},
   "outputs": [],
   "source": [
    "#High R² vs. Low Adjusted R² in Multiple Linear Regression\n",
    "#A high R² value indicates that a large proportion of the variance in the dependent variable is explained\n",
    "#by the independent variables in the model. However, if the adjusted R² value is low, it suggests that \n",
    "#the model's performance may not be as strong as initially indicated by the high R² value.\n",
    "\n",
    "#Reasons for the Discrepancy\n",
    "#1. Overfitting: A high R² value can be inflated by overfitting, where the model is too complex and\n",
    "#fits the noise in the training data rather than the underlying signal. The adjusted R² value penalizes\n",
    "#for model complexity, providing a more conservative estimate of model performance.\n",
    "#2. Number of Predictors: When there are many predictors in the model, R² can be artificially inflated.\n",
    "#The adjusted R² value takes into account the number of predictors and provides a more accurate assessment\n",
    "#of model performance.\n",
    "#3. Lack of Parsimony: A model with a high R² value but low adjusted R² value may indicate that the model\n",
    "#is not parsimonious, meaning it includes unnecessary variables that do not contribute significantly to the\n",
    "#model's explanatory power.\n",
    "\n",
    "#Implications\n",
    "#1. Model Evaluation: A high R² value may not be sufficient to evaluate model performance.\n",
    "#The adjusted R² value provides a more comprehensive assessment of model fit, taking into account model \n",
    "#complexity and parsimony.\n",
    "#2. Model Selection: When comparing models, it's essential to consider both R² and adjusted R² values.\n",
    "#A model with a higher adjusted R² value may be preferred over a model with a higher R² value but \n",
    "#lower adjusted R² value.\n",
    "#3. Model Refining: A low adjusted R² value may indicate that the model needs to be refined by removing\n",
    "#unnecessary variables, transforming variables, or considering alternative models.\n",
    "\n",
    "#Actionable Steps\n",
    "#1. Model Simplification: Consider simplifying the model by removing unnecessary variables or using \n",
    "#dimensionality reduction techniques.\n",
    "#2. Regularization Techniques: Regularization techniques, such as Lasso or Ridge regression, can help \n",
    "#reduce overfitting and improve model performance.\n",
    "#3. Cross-Validation: Use cross-validation techniques to evaluate model performance on unseen data and \n",
    "#prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4973745-2833-4c65-8e45-1ce2b3abe1a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "86bd7d0f-76d1-41cc-be64-f128ca10a424",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q22. Why is it important to scale variables in Multiple Linear Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2360a35e-0d83-4f59-a57f-6432f63332db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importance of Scaling Variables in Multiple Linear Regression\n",
    "#Scaling variables is a crucial step in Multiple Linear Regression (MLR) that ensures all variables\n",
    "#are on the same scale, which can improve the stability and interpretability of the model.\n",
    "\n",
    "#Reasons for Scaling Variables\n",
    "#1. Prevents Feature Dominance: When variables are on different scales, those with larger ranges \n",
    "#can dominate the model, leading to biased coefficients and incorrect inferences. Scaling variables\n",
    "#prevents feature dominance and ensures that all variables contribute equally to the model.\n",
    "#2. Improves Model Stability: Scaling variables can improve the numerical stability of the model,\n",
    "#reducing the risk of multicollinearity and improving the accuracy of coefficient estimates.\n",
    "#3. Enhances Interpretability: Scaling variables can make it easier to interpret the coefficients \n",
    "#and understand the relationships between variables.\n",
    "\n",
    "#Consequences of Not Scaling Variables\n",
    "#1. Biased Coefficients: Failing to scale variables can result in biased coefficients, leading to\n",
    "#incorrect inferences about the relationships between variables.\n",
    "#2. Incorrect Feature Importance: Without scaling, feature importance may be misjudged, leading to\n",
    "#incorrect conclusions about the most influential variables.\n",
    "#3. Model Instability: Failing to scale variables can lead to model instability, resulting in poor\n",
    "#predictive performance and unreliable estimates.\n",
    "\n",
    "#Methods for Scaling Variables\n",
    "#1. Standardization: Standardization involves subtracting the mean and dividing by the \n",
    "#standard deviation for each variable, resulting in a mean of 0 and a standard deviation of 1.\n",
    "#2. Normalization: Normalization involves scaling variables to a common range, often between 0 and 1,\n",
    "#to prevent feature dominance and improve model stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc674a4-7d1e-4c4d-908f-9176a5a1104d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "23f4ea13-d079-4ea9-b4d4-a4ee5e75b060",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q23. What is polynomial regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "06e056d8-4bce-4c61-885e-c4c3f1b3f9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Polynomial Regression\n",
    "#Polynomial regression is a type of regression analysis where the relationship between the \n",
    "#independent variable and the dependent variable is modeled as a polynomial equation. \n",
    "#This allows for more complex, non-linear relationships to be captured, making it a powerful tool \n",
    "#for modeling real-world phenomena.\n",
    "\n",
    "#Key Characteristics\n",
    "#1. Non-Linear Relationship: Polynomial regression models non-linear relationships between variables, \n",
    "#allowing for more complex interactions to be captured.\n",
    "#2. Polynomial Equation: The relationship is modeled using a polynomial equation of a specified degree,\n",
    "#which can be quadratic, cubic, or higher-order.\n",
    "#3. Flexibility: Polynomial regression offers flexibility in modeling various types of relationships,\n",
    "#making it suitable for a wide range of applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327b64b4-17c6-45cd-b5cd-7dbc32d4db03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fd65d8f1-5183-47e6-a357-056cfd0e1a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q24. How does polynomial regression differ from linear regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e5aa4706-42cc-4ba9-aaed-5601e14fa80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Polynomial Regression vs. Linear Regression\n",
    "#Polynomial regression and linear regression are both types of regression analysis used to model \n",
    "#relationships between variables. However, they differ in the type of relationship they model and \n",
    "#the complexity of the model.\n",
    "\n",
    "#Key Differences\n",
    "#1. Relationship Type:\n",
    "#- Linear Regression: Models a linear relationship between the independent variable(s) and the \n",
    "#dependent variable.\n",
    "#- Polynomial Regression: Models a non-linear relationship between the independent variable(s) \n",
    "#and the dependent variable using a polynomial equation.\n",
    "#2. Model Complexity:\n",
    "#- Linear Regression: A simple, linear model that assumes a straight-line relationship.\n",
    "#- Polynomial Regression: A more complex model that can capture non-linear relationships, with \n",
    "#the degree of the polynomial determining the complexity.\n",
    "#3. Equation Form:\n",
    "#- Linear Regression: The relationship is modeled using a linear equation of the form y = β0 + β1x + ε.\n",
    "#- Polynomial Regression: The relationship is modeled using a polynomial equation of the form \n",
    "#y = β0 + β1x + β2x^2 + … + βnx^n + ε.\n",
    "\n",
    "#Implications of the Differences\n",
    "#1. Flexibility:\n",
    "#- Polynomial Regression offers more flexibility in modeling complex relationships, while linear \n",
    "#regression is limited to linear relationships.\n",
    "#2. Interpretability:\n",
    "#- Linear regression models are often more interpretable due to their simplicity, while polynomial\n",
    "#regression models can be more challenging to interpret due to their complexity.\n",
    "#3. Risk of Overfitting:\n",
    "#- Polynomial regression models are more prone to overfitting, especially when the degree of the \n",
    "#polynomial is high, while linear regression models are less likely to overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc90b2e-85e6-4c77-ba87-44e04906cf25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dfb1acb4-e272-446c-ad66-a2de4731a511",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q25. When is polynomial regression used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bce2e263-afdd-4778-ab9a-23f0958994b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Polynomial Regression Use Cases\n",
    "#Polynomial regression is used when the relationship between the independent variable(s) and the \n",
    "#dependent variable is non-linear and can be modeled using a polynomial equation. Here are some \n",
    "#scenarios where polynomial regression is particularly useful:\n",
    "\n",
    "#Non-Linear Relationships\n",
    "#1. Curvilinear Relationships: When the relationship between variables is curvilinear, polynomial \n",
    "#regression can capture the non-linear pattern.\n",
    "#2. Complex Interactions: Polynomial regression can model complex interactions between variables,\n",
    "#allowing for more accurate predictions.\n",
    "\n",
    "#Real-World Applications\n",
    "#1. Physics and Engineering: Polynomial regression is used to model complex physical phenomena, \n",
    "#such as the trajectory of projectiles or the behavior of electrical circuits.\n",
    "#2. Economics: Polynomial regression can be used to model non-linear relationships in economic data,\n",
    "#such as the relationship between GDP and inflation.\n",
    "#3. Biology: Polynomial regression is used in biology to model non-linear relationships between variables,\n",
    "#such as the growth rate of populations or the response of organisms to environmental factors.\n",
    "\n",
    "#Data Characteristics\n",
    "#1. Non-Linear Trends: When the data exhibits non-linear trends, polynomial regression can be used to \n",
    "#capture these patterns.\n",
    "#2. Non-Normal Distributions: Polynomial regression can be used when the data does not follow a normal\n",
    "#distribution, as it can handle non-linear relationships.\n",
    "\n",
    "#Model Requirements\n",
    "#1. Flexibility: Polynomial regression is useful when a flexible model is required to capture complex relationships.\n",
    "#2. Non-Linear Modeling: When a non-linear model is necessary to accurately capture the relationship between variables, polynomial regression is a suitable choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bff3e08-2484-4283-8bb7-1cbe6c7accb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d486eb53-cb96-466b-92b4-1e1fc668c516",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q26. What is the general equation for polynomial regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ab24b696-6dfe-4367-816d-7a289c743c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Polynomial Regression Equation\n",
    "#The general equation for polynomial regression of degree n is given by:\n",
    "\n",
    "#y = β0 + β1x + β2x^2 + β3x^3 + … + βnx^n + ε\n",
    "\n",
    "#Where:\n",
    "\n",
    "#- y is the dependent variable\n",
    "#- x is the independent variable\n",
    "#- β0, β1, β2, …, βn are the coefficients of the polynomial\n",
    "#- n is the degree of the polynomial\n",
    "#- ε is the error term\n",
    "\n",
    "#Special Cases\n",
    "#1. Linear Regression (Degree 1): y = β0 + β1x + ε\n",
    "#2. Quadratic Regression (Degree 2): y = β0 + β1x + β2x^2 + ε\n",
    "#3. Cubic Regression (Degree 3): y = β0 + β1x + β2x^2 + β3x^3 + ε\n",
    "\n",
    "#Key Components\n",
    "#1. Coefficients (β): The coefficients of the polynomial equation represent the change in the dependent\n",
    "#variable for a one-unit change in the independent variable, while holding all other terms constant.\n",
    "#2. Degree of the Polynomial (n): The degree of the polynomial determines the complexity of the relationship\n",
    "#between the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f79f33-1087-467d-b36f-caa83db3b171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f0cb7a0a-fe25-4e76-8e9f-de6d122b5fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q27.Can polynomial regression be applied to multiple variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b2ae3bf1-68c5-43aa-b576-5f8f14934250",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Polynomial Regression with Multiple Variables\n",
    "#Yes, polynomial regression can be applied to multiple variables. This is known as multivariate \n",
    "#polynomial regression.\n",
    "\n",
    "#Multivariate Polynomial Regression Equation\n",
    "#The general equation for multivariate polynomial regression is given by:\n",
    "\n",
    "#y = β0 + Σβixi + Σβijxixj + Σβijkxixjxk + … + ε\n",
    "\n",
    "#Where:\n",
    "\n",
    "#- y is the dependent variable\n",
    "#- xi, xj, xk are the independent variables\n",
    "#- β0, βi, βij, βijk are the coefficients of the polynomial\n",
    "#- ε is the error term\n",
    "\n",
    "#Key Aspects\n",
    "#1. Interactions between Variables: Multivariate polynomial regression can capture interactions between\n",
    "#variables, allowing for more complex relationships to be modeled.\n",
    "#2. Higher-Order Terms: The model can include higher-order terms, such as squared or cubed terms, to capture\n",
    "#non-linear relationships.\n",
    "#3. Increased Complexity: Multivariate polynomial regression models can become increasingly complex, requiring\n",
    "#careful selection of terms and regularization techniques to prevent overfitting.\n",
    "\n",
    "#Applications\n",
    "#1. Multi-Factor Models: Multivariate polynomial regression is useful for modeling relationships between \n",
    "#multiple independent variables and a dependent variable.\n",
    "#2. Complex Systems: This technique can be applied to complex systems where multiple variables interact in \n",
    "#non-linear ways.\n",
    "\n",
    "#Challenges\n",
    "#1. Model Selection: Selecting the correct terms and degree of the polynomial can be challenging,\n",
    "#requiring careful evaluation of model performance.\n",
    "#2. Overfitting: Multivariate polynomial regression models are prone to overfitting, requiring \n",
    "#regularization techniques to prevent this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3b1b03-0b3c-4f2d-84f9-959811914ec4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "17163daa-065b-499e-931d-33a72d03f89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q28. What are the limitations of polynomial regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "09ef5feb-6a23-4784-b00d-f47061978295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limitations of Polynomial Regression\n",
    "#While polynomial regression is a powerful tool for modeling non-linear relationships, it has several\n",
    "#limitations that need to be considered.\n",
    "\n",
    "#1. Overfitting\n",
    "#- High-Degree Polynomials: High-degree polynomials can lead to overfitting, where the model fits the \n",
    "#noise in the training data rather than the underlying pattern.\n",
    "#- Increased Risk with More Variables: The risk of overfitting increases with the number of variables\n",
    "#and the degree of the polynomial.\n",
    "\n",
    "#2. Computational Complexity\n",
    "#- Increased Computational Cost: As the degree of the polynomial increases, the computational cost of \n",
    "#fitting the model also increases.\n",
    "#- Numerical Instability: High-degree polynomials can lead to numerical instability, making it challenging\n",
    "#to estimate the coefficients accurately.\n",
    "\n",
    "#3. Lack of Interpretability\n",
    "#- Complex Models: Polynomial regression models can become complex and difficult to interpret, especially\n",
    "#when dealing with high-degree polynomials or multiple variables.\n",
    "#- Difficulty in Identifying Relationships: It can be challenging to identify the relationships between \n",
    "#variables and understand the impact of each term on the dependent variable.\n",
    "\n",
    "#4. Extrapolation Issues\n",
    "#- Poor Performance Outside Training Range: Polynomial regression models can perform poorly when \n",
    "#extrapolating outside the range of the training data.\n",
    "#- Unpredictable Behavior: The model can exhibit unpredictable behavior when extrapolating, leading\n",
    "#to inaccurate predictions.\n",
    "\n",
    "#5. Sensitivity to Outliers\n",
    "#- Impact of Outliers: Polynomial regression models can be sensitive to outliers, which can significantly\n",
    "#impact the fit of the model.\n",
    "#- Robustness Issues: The model may not be robust to outliers, leading to biased estimates and poor predictions.\n",
    "\n",
    "#6. Model Selection Challenges\n",
    "#- Choosing the Correct Degree: Selecting the correct degree of the polynomial can be challenging,\n",
    "#requiring careful evaluation of model performance.\n",
    "#- Balancing Fit and Complexity: There is a trade-off between fit and complexity, and selecting the \n",
    "#optimal degree of the polynomial requires balancing these competing factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668fd483-ac11-4ff0-90be-9e32c6fab2b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3bbba96d-526a-435b-aa30-942e233d985e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q29. What methods can be used to evaluate model fit when selecting the degree of a polynomial?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9e003e92-7daa-43b1-aed4-e326609792c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating Model Fit for Polynomial Regression\n",
    "#When selecting the degree of a polynomial, it's essential to evaluate the model fit to ensure \n",
    "#that the chosen degree provides the best balance between fit and complexity. Here are some methods\n",
    "#that can be used to evaluate model fit:\n",
    "\n",
    "#1. Visual Inspection\n",
    "#- Plotting the Data: Visualize the data and the fitted model to assess the fit.\n",
    "#- Residual Plots: Plot the residuals against the fitted values or the independent variable to check \n",
    "#for patterns or trends.\n",
    "\n",
    "#2. Goodness-of-Fit Metrics\n",
    "#- R-Squared (R²): Measures the proportion of variance explained by the model.\n",
    "#- Adjusted R-Squared: Adjusts R² for the number of predictors in the model.\n",
    "#- Mean Squared Error (MSE): Measures the average squared difference between observed and\n",
    "#predicted values.\n",
    "#- Root Mean Squared Error (RMSE): Square root of MSE, providing a measure of the spread \n",
    "#of the residuals.\n",
    "\n",
    "#3. Cross-Validation\n",
    "#- K-Fold Cross-Validation: Splits the data into k folds, trains the model on k-1 folds, and evaluates\n",
    "#on the remaining fold.\n",
    "#- Leave-One-Out Cross-Validation (LOOCV): Special case of k-fold cross-validation where k equals the\n",
    "#number of observations.\n",
    "\n",
    "#4. Information Criteria\n",
    "#- Akaike Information Criterion (AIC): Measures the relative quality of a model, balancing fit and complexity.\n",
    "#- Bayesian Information Criterion (BIC): Similar to AIC, but with a stronger penalty for complexity.\n",
    "\n",
    "#5. Hypothesis Testing\n",
    "#- F-Test: Tests the significance of the regression model and can be used to compare nested models.\n",
    "#- t-Tests: Tests the significance of individual coefficients in the model.\n",
    "\n",
    "#6. Regularization Techniques\n",
    "#- Lasso Regression: Adds a penalty term to the loss function to reduce the magnitude of coefficients,\n",
    "#effectively selecting the most important terms.\n",
    "#- Ridge Regression: Similar to Lasso, but with a different penalty term that reduces the magnitude of \n",
    "#coefficients without setting them to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21fd83b-9d6a-411a-ae2e-d10f435d9fb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2316105e-15bb-4c3a-af1e-f75e4e792c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q30. Why is visualization important in polynomial regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "edd9a332-d8e2-4de5-9f2a-668102468d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importance of Visualization in Polynomial Regression\n",
    "#Visualization plays a crucial role in polynomial regression, enabling a deeper understanding \n",
    "#of the relationships between variables and the model's performance.\n",
    "\n",
    "#Understanding Relationships\n",
    "#1. Non-Linear Patterns: Visualization helps identify non-linear patterns in the data, which polynomial \n",
    "#regression can capture.\n",
    "#2. Relationship between Variables: Plotting the data reveals the relationship between the independent\n",
    "#variable(s) and the dependent variable.\n",
    "\n",
    "#Model Evaluation\n",
    "#1. Goodness of Fit: Visualization helps assess the goodness of fit of the model, revealing whether the \n",
    "#polynomial degree is sufficient or if the model is overfitting/underfitting.\n",
    "#2. Residual Patterns: Plotting residuals against fitted values or independent variables helps identify\n",
    "#patterns or trends that the model may not have captured.\n",
    "\n",
    "#Model Selection\n",
    "#1. Comparing Models: Visualization enables comparison of different polynomial degrees, helping select\n",
    "#the best model.\n",
    "#2. Identifying Overfitting: Visualization can reveal signs of overfitting, such as wiggly curves or poor \n",
    "#generalization to new data.\n",
    "\n",
    "#Interpretation and Communication\n",
    "#1. Insights into Relationships: Visualization provides insights into the relationships between variables,\n",
    "#facilitating interpretation of the results.\n",
    "#2. Communicating Results: Visualizations are effective for communicating complex results to non-technical\n",
    "#stakeholders.\n",
    "\n",
    "#Common Visualization Techniques\n",
    "#1. Scatter Plots: Plot the data points to visualize the relationship between variables.\n",
    "#2. Fitted Curve Plots: Plot the fitted curve to visualize the model's performance.\n",
    "#3. Residual Plots: Plot residuals against fitted values or independent variables to assess model fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf16068-7b88-4d69-aa5c-210ad67c38e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e5e2cb97-2c79-4d25-8031-e92df31a6f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q31.How is polynomial regression implemented in Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "72622098-f6d4-446a-98a5-29d804df0f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementing Polynomial Regression in Python\n",
    "#Polynomial regression can be implemented in Python using the scikit-learn library, which provides a simple\n",
    "#and efficient way to fit polynomial models.\n",
    "\n",
    "#Required Libraries\n",
    "#- scikit-learn: For polynomial regression implementation\n",
    "#- numpy: For numerical computations\n",
    "#- matplotlib: For visualization\n",
    "\n",
    "#Implementation Steps\n",
    "#1. Import Libraries: Import the required libraries, including scikit-learn's PolynomialFeatures \n",
    "#and LinearRegression classes.\n",
    "#2. Generate Polynomial Features: Use PolynomialFeatures to generate polynomial features from the\n",
    "#independent variable(s).\n",
    "#3. Fit the Model: Fit a linear regression model to the polynomial features using LinearRegression.\n",
    "#4. Make Predictions: Use the fitted model to make predictions on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "93313ad3-b630-4693-abfa-cda378c1f96e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Example\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(-10, 10, 100).reshape(-1, 1)\n",
    "y = 3* x**2 + 2 * x + 1 + np.random.randn(100, 1)\n",
    "poly_features = PolynomialFeatures(degree=2)\n",
    "x_poly = poly_features.fit_transform(x)\n",
    "model = LinearRegression()\n",
    "model.fit(x_poly, y)\n",
    "y_pred = model.predict(x_poly)\n",
    "plt.scatter(x, y, label=\"Data\")\n",
    "plt.plot(x, y_pred, label=\"Polynomial Regression\", color=\"red\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80af142a-b357-4fb7-908e-586e11e47926",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee943cf-3c52-4bf7-9298-9d260e65a922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad5c4f8-0acd-49a8-8387-63e411a0523d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c00a52-984e-45c8-8462-7b049c28eef8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
